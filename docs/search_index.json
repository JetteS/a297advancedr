[["index.html", "A297 Advanced R PhD course offered by the Graduate School of Health, Aarhus University Preface How to read this book License", " A297 Advanced R PhD course offered by the Graduate School of Health, Aarhus University Jette Steinbach 2024-08-21 Preface This document is a modification of the book advr38book by Florian Privé. Florian originally developed the materials for the doctoral school of Grenoble, France, but now they are used as the main course material for the PhD course Advanced R offered by the Graduate School of Health, Aarhus University, Denmark. The main aim of this book is to give the reader a greater understanding of the R language, and to enable them to produce more clean, sophisticated and efficient R code. The reader will learn about packages and tools to simplify their coding life, about data analysis and visualization, and about best practices when coding in R. After studying these materials, the reader should be able to use RStudio with a better setup to be more efficient use Git as a version control system to track file changes understand how to write better and simpler code in R manipulate and visualize data with the tidyverse and R Markdown produce efficient R code develop an R package. How to read this book Readers are recommended to have a basic understanding of R and some experience writing R code. You should, for example, be able to create variables, define functions, implement loops and subset objects such as vectors and data frames. If you are new to R, you can take a look at Garrett Grolemund’s Hands-On Programming with R (2014), a book that uses hands-on examples to teach you how to program in R. Some other useful resources are Basic Basics, a lesson unit from R-Ladies Sydney providing an opinionated tour of RStudio for new users and a step-by-step guide to installing and using R packages. A Gentle Introduction to Tidy Statistics in R (Thomas Mock, 2019), a one-hour free video webinar about how to get started quickly with basics of research statistics in R. Posit Recipes, a collection of R code snippets and instructions featuring up-to-date best practices for coding in R. The RStudio Essentials Series, a webinar series about how to program and manage R projects using RStudio’s tools. These videos will also help you learn good development practices. Finally, posit also provides some very useful cheatsheets, for example about the RStudio IDE, that you may find helpful. In total, this book consists of eight chapters. The first chapter is a short introduction covering prerequisites, content and other useful resources. The following six chapters are theoretical and cover the following topics Good practices Advanced R programming R Markdown Data analysis with the tidyverse Code performance How to make an R package The final chapter is an opportunity for the reader to apply the new theory using real data from Tidy Tuesday. The reader does not need to read through the materials from beginning to end. I have tried to make each chapter as self-contained as possible, and the reader should be able to only read the parts that are most interesting or relevant. License This material is licensed under the Creative Commons Attribution-ShareAlike 3.0 License. "],["introduction.html", "Chapter 1 Introduction Prerequisites Content Useful resources", " Chapter 1 Introduction Prerequisites To get the most out of these materials, you should have a basic understanding of R and some experience writing R code. You should, for example, be able to create variables, define functions, implement loops and subset objects such as vectors and data frames. Furthermore, you should install the most recent version of R. In this book, we will use R version 4.4.1. Make sure that you have installed R version &gt;= 4.4.1 to run the examples and exercises provided throughout these materials. You can get your current version with version[['version.string']] or R.Version()$version.string. Once you have downloaded and installed the desired version of R, go to Tools &gt; Global Options... and change the R version. Remember to restart R afterwards. Your browser does not support the video tag. install the most recent version of RStudio. In this book, we will use RStudio version 2024.04.2. You can get the current version of your R Studio by opening Help &gt; About RStudio (on Windows) or RStudio &gt; About RStudio (on Mac). install the package advr38pkg with remotes::install_github(\"privefl/advr38pkg\"). This will also install other dependencies needed in this book. Please note that you might need to install the package remotes first using install.packages(\"remotes\"). install Git. Once the version control system has been installed, you need to activate it. Go to Tools &gt; Global Options &gt; Git/SVN and click Enable version control interface for RStudio projects. If necessary, enter the path for the Git executable. Your browser does not support the video tag. create a GitHub account. Content It is impossible to become an expert in R in one training course only. Yet, these materials aim at giving a wide understanding of many aspects of R. This is done by breaking the book into smaller parts, each covering a single aspect of R. Chapter 2 covers good practices in R, i.e. good coding style, using the RStudio IDE, version control, and how to get help when you are stuck. Chapter 3 introduces base R concepts that are important to really understand R as a programming language. These concepts are base R objects, their types and accessors, useful base R functions, environments and scoping, along with attributes and classes. Chapter 4 is an introduction to R Markdown. Chapter 5 introduces data analysis with the tidyverse. In this chapter, I will introduce tidy data and tibbles, transform data with dplyr, and visualize data with ggplot2. Chapter 6 is all about performance: R’s memory management, vectorization, Rcpp, linear algebra, algorithms and data structures along with parallel computing. In Chapter 7, we will look at how to make an R package. The final chapter, Chapter 8, introduces Tidy Tuesday. In this chapter you will also find a project that you can make if you want to apply the theory to real data. You do not need to read through the materials from beginning to end. I have tried to make each chapter as self-contained as possible, and you should be able to only read the parts that are most interesting or relevant to you. Most chapters do refer to external resources that you can use to deepen what you have learned in this book. You will find these resources at the end of each chapter. Useful resources Course on R debugging and robust programming by Laurent Gatto &amp; Robert Stojnic, Data Challenge Lab by Hadley Wickham, Advanced R by Hadley Wickham, and some solutions, R for Data Science by Garrett Grolemund &amp; Hadley Wickham, and some solutions, R packages by Hadley Wickham, Efficient R programming by Colin Gillespie &amp; Robin Lovelace, R Programming for Data Science by Roger D. Peng, Mastering Software Development in R by Roger D. Peng, Sean Kross and Brooke Anderson. "],["good-practices.html", "Chapter 2 Good practices 2.1 Coding style 2.2 RStudio 2.3 Version control (Git) 2.4 When things go wrong… 2.5 Summary Useful resources", " Chapter 2 Good practices In the following, we will consider some good practices for writing R code. But before we dive into that topic, let us explain why code needs to be clean and efficient. First, if you are working in a team, writing efficient and clean code makes it a lot easier for you colleagues to understand, debug and improve it. If you want your colleagues or collaborators to reuse your code, it should be readable and easy to follow. Second, you can spare your future self a lot of frustration by writing clean code from the beginning. By doing that, you won’t have to ask yourself What the hell am I doing in this function? 2.1 Coding style Good coding style is like correct punctuation: you can manage without it, butitsuremakesthingseasiertoread. — Hadley Wickham Please make your code readable by following the available style guides. We recommend you take a look at the tidyverse style guide. In the following, we provide some examples from this guide. 2.1.1 Naming Be smart with your naming. You won’t believe how often we have seen df &lt;- as.matrix(mtcars) on Stack Overflow. Use meaningful and concise names for your files, data sets, and functions; you will save yourself a lot of time. For example, consider the following piece of code dat1 &lt;- tidytuesdayR::tt_load(&quot;2020-01-14&quot;)[[1]] dat2 &lt;- dat1[dat1$category == &quot;animal&quot;,] dat3 &lt;- dat1[dat1$strength == 7,] fct1 &lt;- function(tbl, n = 5) { tbl &lt;- tbl[complete.cases(tbl$rank),] tbl[tbl$rank &lt;= n, 2] } Looking only at this code, do you have any idea what data is stored in dat1, dat2 and dat3? Not really, right? Now imagine, you have 500 lines of code analyzing and visualizing the three different data sets using numerous functions. You would probably get confused about the different data sets and functions quite quick. Now consider the following lines of code passwords &lt;- tidytuesdayR::tt_load(&quot;2020-01-14&quot;)[[1]] password_category &lt;- passwords[passwords$category == &quot;animal&quot;, ] password_strength &lt;- passwords[passwords$strength == 7, ] get_popular_passwords &lt;- function(tbl, n = 5) { tbl &lt;- tbl[complete.cases(tbl$rank), ] tbl[tbl$rank &lt;= n, 2] } This code is identical to the previous code; except for the names. But it is much easier to read and understand. Let us improve the code even more by adding comments. # Loading the passwords data passwords &lt;- tidytuesdayR::tt_load(&quot;2020-01-14&quot;)[[1]] # Extracting passwords within the category &quot;animal&quot; password_category &lt;- passwords[passwords$category == &quot;animal&quot;, ] # Extracting passwords with a quality of 7 password_strength &lt;- passwords[passwords$strength == 7, ] # Function: extracts the n most popular passwords get_popular_passwords &lt;- function(tbl, n = 5) { tbl &lt;- tbl[complete.cases(tbl$rank), ] tbl[tbl$rank &lt;= n, 2] } When commenting code, you should focus on explaining the “why” instead of the “what” or “how”. Comments should be in sentence case, and only end with a full stop if they contain at least two sentences. Suggestions for naming: For files names, use underscore separated strings. All words should be lower case, e.g. fit_models.R or utility_functions.R (with consideration for operating systems with a case-sensitive file systems). Never have file names that only differ in their capitalization! Avoid using special characters in file names. For function names, use only lowercase letters and numbers separated by an underscore (_), e.g. compute_mean. Avoid using dots in function names, as they should be reserved exclusively for the S3 object system. Generally, function names should be verbs. For variable names, use only lowercase letters and numbers separated by an underscore (_), e.g. day_1. Avoid re-using names of common functions and variables (such as mean, c or T), as this may cause confusion for the readers. Generally, variable names should be nouns. 2.1.2 Spacing Place a space before and after = when naming arguments in function calls. Most infix operators (==, +, -, &lt;-, etc.) are also surrounded by spaces, except those with high precedence (^, :, ::, and :::, $, [, [[), !! (bang-bang) and !!! (bang-bang-bang) when used in tidy evaluation, the help operator ?. # Good average &lt;- mean((feet / 12) + inches, na.rm = TRUE) x &lt;- 1:10 base::sum ?mean # Unfortunate average&lt;-mean(feet/12+inches,na.rm=TRUE) x &lt;- 1 : 10 base :: sum ? mean Always put a space after a comma, and never before (just like in regular English): # Good x[, 1] # Unfortunate x[,1] x[ ,1] x[ , 1] For parenthesis, there are three different rules. When parentheses are used in connection to regular function calls, they are not surround by space: # Good mean(x, na.rm = TRUE) # Unfortunate mean (x, na.rm = TRUE) mean( x, na.rm = TRUE ) However, when the parentheses are used with if, for, or while, they are surrounded by space: # Good if (debug) { show(x) } # Unfortunate if(debug){ show(x) } When the parentheses are used for function arguments, you put a space after the closing parenthesis ): # Good function(x) {} # Unfortunate function (x) {} function(x){} Finally, the pipe %&gt;% should always have a space before it, and it is usually followed by a new line: # Good iris %&gt;% group_by(Species) %&gt;% summarize_if(is.numeric, mean) %&gt;% ungroup() %&gt;% gather(measure, value, -Species) %&gt;% arrange(value) # Unfortunate iris %&gt;% group_by(Species) %&gt;% summarize_all(mean) %&gt;% ungroup %&gt;% gather(measure, value, -Species) %&gt;% arrange(value) We will return to the pipe operator in Chapter 5. The same styling suggestions also hold for the operator that separates ggplot2 layers, +. You will meet this operator again in Chapter 5. 2.1.3 Indenting Curly braces, {}, define the most important hierarchy of R code. To make this hierarchy easy to see, always indent the code inside {} by two spaces. This should be automatic in RStudio. # Good if (y &lt; 0 &amp;&amp; debug) { message(&quot;y is negative&quot;) } if (y == 0) { if (x &gt; 0) { log(x) } else { message(&quot;x is negative or zero&quot;) } } else { y ^ x } # Unfortunate if (y &lt; 0 &amp;&amp; debug) message(&quot;Y is negative&quot;) if (y == 0) { if (x &gt; 0) { log(x) } else { message(&quot;x is negative or zero&quot;) } } else { y ^ x } 2.1.4 Long lines Strive to limit your code to 80 characters per line. This fits comfortably on your screen with a reasonably sized font. If you find yourself running out of room, this is a good indication that you should encapsulate some of the work in a separate function. To change the margin in RStudio go to Tools -&gt; Global Options -&gt; Code -&gt; Display, and set Margin column: to 80. Your browser does not support the video tag. 2.1.5 Other Use &lt;-, not =, for assignment. Keep = for parameters. # Good x &lt;- 5 system.time( x &lt;- rnorm(1e6) ) # Unfortunate x = 5 system.time( x = rnorm(1e6) ) Don’t end a line of code with ;, and avoid multiple commands on the same line. Only use return() for early returns. Otherwise rely on R to return the result of the last evaluated expression. Moreover, return statements should always be on their own line. # Good add_two &lt;- function(x, y) { x + y } # Unfortunate add_two &lt;- function(x, y) { return(x + y) } Use \", not ', for quoting text. The only exception is when the text already contains double quotes and no single quotes. # Good &quot;Text&quot; &#39;Text with &quot;quotes&quot;&#39; &#39;&lt;a href=&quot;http://style.tidyverse.org&quot;&gt;A link&lt;/a&gt;&#39; # Unfortunate &#39;Text&#39; &#39;Text with &quot;double&quot; and \\&#39;single\\&#39; quotes&#39; Use TRUE and FALSE instead of T and F. 2.1.6 Code organization The way the code is organized within a single file significantly impacts the readability. We suggest to start each file with a comment holding a description of the file, who wrote it, and when it was last updated. You may want to set a default template that is used each time you open a new .R script. To do this, you have to create a templates folder in AppData/Roaming/RStudio/ and include a default.R file with the desired template. # Create a template folder fs::dir_create(path = &quot;~/AppData/Roaming/RStudio/templates&quot;) # Create the file fs::file_create(path = &quot;~/AppData/Roaming/RStudio/templates/default.R&quot;) # Open the file in RStudio usethis::edit_file(&quot;~/AppData/Roaming/RStudio/templates/default.R&quot;) For example, you can add the following comments to default.R: ###################################################################### ## Title : ## ## Description : ## ## Author : ## ## Date : ###################################################################### ## ## Loading required libraries:######################################## Remember to save the changes you made to default.R. After the comment section, you should load all required add-on packages using library(). This is more transparent than having many library() calls throughout your entire code. Afterwards, any required files should be sourced using source(). Again, this is more transparent than having many source() calls throughout your entire code. Finally, you can start your code. Within your code, use commented lines of -, = or # to break up your file into smaller bits. 2.1.7 Styler You can use the package styler to correct your style. It even has RStudio Addins. Once you have installed the package using install.packages(\"styler\"), you can format your code according to the tidyverse style guide (or your custom style guide) through the RStudio addin as demonstrated below, or through R functions like style_text(), style_file() or style_pkg(). In RStudio, you can also use the shortcut Ctrl+Shift+A (Windows and Linux) or Shift+Command+A (Mac) to reformat selected code. We will talk about RStudio shortcuts in the next section (2.2). 2.2 RStudio Download a recent enough version of the RStudio IDE (see Prerequisites in Chapter 1 for details). These materials are based on RStudio version 2024.04.2, and we recommend that you use that or any newer version. Once you have installed RStudio, use it! RStudio comes with many tools and features, for example everything you can expect from a good integrated development environment (IDE) useful keyboard shortcuts. We often use the following shortcuts (Windows or Linux / Mac) Ctrl+Space / Command+Space for auto-completion (better than Tab) Ctrl+Up / Command+Up to show and search the command history in a popup Ctrl+Click / Command+Click to see a function’s source code Ctrl+Enter / Command+Return to execute current line/selection of code Ctrl+Shift+A / Shift+Command+A to reformat current selection of code Ctrl+Shift+C / Shift+Command+C to comment/uncomment selected lines Ctrl+Shift+K / Shift+Command+K to knit a document (you will need this in Chapter 4) Ctrl+Shift+B / Shift+Command+B to build a package, website or book (you will learn how to build a package in Chapter 7) Ctrl+Shift+M / Shift+Command+M to insert the pipe operator (we use this shortcut all of the time when working in the tidyverse!) Alt+Shift+K / Option+Shift+K to see more keyboard shortcuts. You can find all keyboard shortcuts by using the keyboard shortcut Alt+Shift+K / Option+Shift+K and click on See All Shortcuts in the upper right corner of the window. You can also find them under the Tools menu Tools -&gt; Keyboard Shortcuts Help -&gt; See All Shortcuts, or you can go to this Support website. Finally, you can also change keyboard shortcuts under the Tools menu Tools -&gt; Modify Keyboard Shortcuts. panels (everything is integrated, including Git and a terminal). You can also change the appearance, pane layout, and more under the Tools menu Tools -&gt; Global Options... -&gt; Appearance/Pane Layout interactive data importation from files and connections (see this webinar): code diagnostics can be enabled and options can be set within the Tools -&gt; Global Options -&gt; Code -&gt; Diagnostics editing pane. When code diagnostics are enabled, RStudio performs static and dynamic analysis of your R code and warns you when it detects problems. RStudio reports any errors or warnings in the left gutter (next to the line number) by a marker (, , ) and by underlining the position in the code. When you mouse over the marker, a popup with a short explanation will appear. Another very useful feature of the RStudio IDE is that it includes RStudio projects. RStudio projects make it straightforward to divide your work into multiple contexts, and keep all files associated with a single project together - input data, R scripts, analytic results, figures, etc. The reason why we advise you to work in RStudio projects is that it doesn’t rely on absolute file paths (in contrast to setting your working directory using setwd()). The chance of setwd() working for anyone besides its author is basically 0 %. And having to hand edit one or more paths every time you take over a project can be extremely annoying. RStudio projects solve this issue by making file paths relative. When your RStudio session is running through an RStudio project file (.Rproj), the current working directory points to the root folder where that .Rproj file is saved. In short, the benefits of using RStudio projects are a meaningful structure in one folder the working directory automatically switches to the project’s folder the last previously open file is loaded into the Source pane the History tab in the Environment pane displays R commands executed in previous sessions. the Files tab in the Output pane displays the associated files and folders in the project any settings associated with the project, such as Git settings, are loaded. Note that you can have a .Rprofile file in the project’s root directory to enable project-specific settings to be loaded each time someone opens the project. You can read more about RStudio projects in Chapter 8 of R for Data Science by Hadley Wickham and Garrett Grolemund, in this Tidyverse blog post, and also in Section 2.5 RStudio of Efficient R programming by Colin Gillespie and Robin Lovelace. 2.3 Version control (Git) A useful feature of RStudio projects is that it enables you to use formal version control. Version control is an important process to back up files, keep track of changes, and simplify collaborations. RStudio currently supports two open source version control systems: Git and Subversion. In these materials, we will focus on Git as a version control system, and we will hook our local repositories up to a remote host, namely GitHub. You can find more information about how to activate Git on your system in Section Prerequisites of Chapter 1. 2.3.1 Why use Git? Have you ever Made changes to code, realized it was a mistake and wanted to revert back? Lost code or had a backup that was too old? Wanted to submit a change to someone’s code? Wanted to share your code, or let other people work on your code? Or are you a PhD student working on a manuscript? But you don’t use Git? Figure 2.1: You don’t use Version Control? In these cases, and probably many others, a version control system should make your life easier (see this Stack Overflow answer). With version control you make your workflow reproducible; something that is not only essential in modern day research, but also saves yourself a lot of frustration: And yes, you should also use version control even if you are mainly working by yourself! See this Stack Overflow question. Moreover, version control is very useful when you want to access your projects from different devices and/or places Another important aspect is that you need version control to get websites for your packages with pkgdown, for your book (like this one!) with bookdown, and for your personal webpage with R Markdown Websites or blogdown. Finally, being able to work with GitHub can be a line on your CV (read more): A lot of students have said to me later, even first-year undergraduates, that using GitHub has helped them a lot when they went for an internship or a research position interview. They are able to say, “Oh, I already have worked with GitHub. I am familiar with it. I know how it works.” So I think they are at least able to put that on their CV and go into a situation where there’s a research or data analysis team and say, “Yeah, sure. I am actually familiar with the same tools that you use.” — Mine Cetinkaya-Rundel, Duke University, RStudio 2.3.2 How to use Git To share your code and collaborate with other, use a Git hosting platform. A Git hosting platform is basically the Google Docs of collaborative coding. The main platforms are GitHub (only free for public repositories, now owned by Microsoft) GitLab (open source &amp; free) Bitbucket (free when you have less than 5 collaborators) any server. As mentioned before, we will focus on GitHub in these materials. Once you have created an account on GitHub, the first step is to create a repository. A repository is a folder that contains files, images, sub folders, etc. related to the same project. Hence, it corresponds to an RStudio project. When you are logged into your GitHub account, you can create a new repository by selecting + in the upper-right corner of any page. Select a concise and meaningful name for the repository, and make sure to initialize the repository with a .README file by checking the box. You don’t need to add .gitignore or a license. If you want to, you can also add a short description. Click Create repository. Once you have created the Git repository, you need to link it to an RStudio project. To link your repository to an RStudio project, you need to generate an SSH key. Click on your avatar in the upper-right corner and go to Settings. In the menu on the left-hand side, select SSH and GPG keys. Now you need to open an RStudio session. Go to Tools -&gt; Global Options... -&gt; Git/SVN, and select Create SSH Key... When you have created a SSH key, select View public key and copy the key to the clipboard. Return to GitHub, and add the newly created SSH key to your GitHub account by selecting New SSH key, adding a title (indicating the device the key is used for) and inserting the key under Key. Save the key to your GitHub account by clicking Add SSH key. Please note that you only have to generate an SSH key once for each new device that you link to your GitHub account. Now that you have generated an SSH key, you can link your repository to an RStudio project by following these steps: Go to the repository that you want to link (for example by clicking on your avatar in the upper-right corner, and selecting Your repositories in the drop-down menu). Click the Code tab of your repository. Above the file list, click the drop-down menu that says &lt;&gt; Code. Select the tab called Local. Under the section Clone, select SSH (do not use HTTPS or GitHub CLI). Copy the URL to the clipboard. Go back to your RStudio session and create a new project (File -&gt; New Project... or by clicking the icon in the upper-right corner and selecting New Project...). Create the project from a version control repository. Select Git to clone a project from a Git repository Paste the URL from the clipboard under Repository URL: and select the path were you want to save your project. Enter the passphrase that you selected when you generated the SSH key. Your GitHub repository will now be cloned . Instead of following the written steps above, you can also follow the video tutorial below. A note for Mac users: you might need to use the terminal for git clone, then create the RStudio project from the existing directory. If you have some permission denied for the public key, you might also need to run ssh-agent -s &amp;&amp; ssh-add &lt;path_to_public_key&gt; (cf. this Stack Overflow answer). In RStudio, you will probably use the Environment pane to interact with Git. However, you can also use the terminal in the Console pane. In any case, you will need the following Git commands git add [file]: add a file to your next commit (stage) git add -A: add all new or modified files to be part of the next commit git commit -m “[commit message]”: snapshot of your code at a specified point in time (you can and you should use this even when having no internet connection) git push: merge your local modifications with the main project git pull: update your local project with the latest version of the main project In the Environment pane, the command add is equivalent to marking one or more files with a tick () in the Git tab, while the other three are represented by Commit, Pull, and Push. When collaborating on a project, you and your co-workers may work on the same file simultaneously. If two people edit the same line of code, Git may not be able to resolve the differences automatically, leading to a merge conflict. When this happens, you have to choose (manually) which changes to incorporate in a new commit. To prevent merge conflicts, we advise you to follow these simple rules: after opening a project, always pull before closing a project, always commit/push Furthermore, you should use git even when you do not have any internet connection (e.g. on a secure server)! If you have never worked with Git on GitHub (or you need a reminder) we suggest you follow this tutorial about GitHub essentials. Other helpful websites are Happy Git and GitHub for the useR Git cheat sheet When things go wrong To fix a mistake Create a new branch with git and manage branches Exercise Fork a repository Go to this GitHub repository created by Florian Privé. Fork the repository by opening the drop-down menu named Fork in the upper-right corner of the main page of the repository and selecting + Create a new fork: Once you have forked the repository, open the settings ( Settings), and change the repository name to [YOURGITHUBNAME].github.io (note that [YOURGITHUBNAME] should be replaced by your GitHub username). Now follow the steps mentioned above to link your repository to an RStudio project. We will work on this RStudio project in Chapter 4. You can find GitHub’s documentation on forking a repository here. 2.4 When things go wrong… You have spent the last three hours writing the best R function. You press Ctrl+Enter (or Command+Return), and #&gt; Error in eval(expr, envir, enclos): Something went wrong! Don’t give up! In this section, we will look at some tools that you can use to find and fix problems. 2.4.1 First: locate the error The first step is to figure out where the error comes from. In some cases, identifying the line of code that causes the error is easy. In other cases, locating the error can be really difficult. A basic solution is to print everything; but that strategy is usually not working well on complex problems. A more robust strategy is needed! Start by looking at the error (or warning) message; does it indicate what line or function causes the problem? In the example below, the warning message indicates that log(y) produced NaNs. As log(y) only occurs once, we know that the problem must be in line 3. for (x in 10:0) { y &lt;- (x - 1) invisible(log(y)) } #&gt; Warning in log(y): NaNs produced You may be able to fix the bug once you have located it. In other situations, especially if you are new to R, the error (or warning) message may not help you at all. In that case, you may want to investigate all variables to check whether they have the desired type. A convenient way to see all the variables’ states in your code is to place use the function browser(). browser() stops the execution of the expression in the line it was invoked from. You are able to inspect the environment and evaluate R expressions in that environment by entering them at the browser prompt. from where you want to check the variables’ states. Try running the following code in your own RStudio session. my_log &lt;- function(x) log(x - 1) my_fun &lt;- function(a, b) { browser() la &lt;- my_log(a) lb &lt;- my_log(b) la + lb } my_fun(1, 0) When you execute line 10, RStudio opens the debug mode. At the top of the console, RStudio now shows a new toolbar that you can use to debug your code: The different buttons execute the following commands: Next : Execute the next line of code : Step into the current function call : Execute the remainder of the current function or loop Continue : Continue execution until the next breakpoint is encountered Stop : Exit debug mode Try using the debug mode to locate the error. One potential problem with browser() is that it is a regular function call; you must add the expression to the code you want to debug. However, sometimes you don’t have the source file for the code you want to debug. When this is the case, you can use the R function debugonce() to flag a function for debugging. When flagging a function for debugging with debugonce(), the function will enter the debugger the very next time it runs, but not after that (hence the name). Try debugonce() to locate the error in my_fun(): debugonce(my_fun) my_fun(1, 0) If you want to debug a function every time it is executed, use the function debug() instead. When you no longer want to debug the function each time it executes, use undebug() on the function. You can read more about debugging in this Support article, Chapter 22 of Advanced R by Hadley Wickham, Chapter 18 of R Programming for Data Science by Roger D. Peng, or this webinar about debugging techniques in RStudio. 2.4.2 Second: fix the error Once you have located the error, you only have to fix it! Well… Not always… Fortunately, someone else probably had the same (or a similar) problem before. Try googling the error message to check whether someone already found the answer to your problem. One of the websites that you will see very often when googling errors thrown by or questions related to R is Stack Overflow. If you cannot find your specific problem on Stack Overflow, you can simply create a new question yourself (using the tag r). The only thing you have to keep in mind is that you need to make a good R reproducible example if you want your question to be answered. You can read the answers to this Stack Overflow questions about how to make minimal reproducible examples (MREs). In some cases, you actually end up understanding and solving the issue, while making an MRE. Reading the documentations carefully is also always a really good idea. Many R packages provide reports or long-form guides, called vignettes, that show a workflow solving a specific problem. The tidyverse, for example, has a variety of good vignettes (e.g. this article comparing dplyr functions to their base R equivalents). A large number of R packages also have a GitHub repository where you can find additional documentation (see, for example, the GitHub repository for tidytuesday). Finally, you can also search for specific R-related sites on https://rseek.org/. 2.4.3 External help You can’t remember all the useful functions provided by a package or how to use a specific function? Use Cheatsheets. Cheatsheets usually provide very nice overviews of packages and their functions, and they even come in different languages. If you are confident enough with your R skills, you can take the next step and answer questions on Stack Overflow. Answering other people’s questions is a good way to increase your skills - or just to procrastinate while writing a scientific manuscript. You can also join communities, e.g. the French-speaking R community on Slack or the R-Ladies community on Slack. These are generally much friendlier and welcoming spaces compared to Stack Overflow. 2.5 Summary Use meaningful and concise names for your files, data sets, and functions. Comment your code and explain why you are doing what you are doing. Follow the available style guides (e.g. the tidyverse style guide). You can use the R package styler to conveniently correct your style. Use the RStudio IDE; It comes with many tools and features (i.e. useful keyboard shortcuts, panels, interactive data importation from files and connections, code diagnostics, and RStudio projects). Use formal version control (Git) even if you are mainly working by yourself! When R throws an error, try to locate it using the error message, browser() or debugonce(). You can get help to fix an error on Stack Overflow. Useful resources Best Coding Practices for R by Grace Hopper Using git from RStudio by Julien Brun RStudio User Guide - Version Control "],["r-programming.html", "Chapter 3 R programming 3.1 Common mistakes to avoid 3.2 Useful R functions 3.3 Data structures in R 3.4 Environments and scoping 3.5 Summary Useful resources", " Chapter 3 R programming In the following, we will consider base R concepts that are important but often overlooked by or unknown to R users. We hope that this chapter will help you to better understand R as a programming language, to avoid common mistakes, and to write more efficient code. Some of the examples used in this chapter are taken from The R Inferno by Patrick Burns, who described his materials in the following way: If you are using R and you think you’re in hell, this is a map for you. — Patrick Burns 3.1 Common mistakes to avoid In the first part of this chapter, we will look at some common mistakes and how to avoid them. 3.1.1 The floating-point error In R, a real number is represented as a floating-point number. A floating-point number is a positive or negative whole number scaled by an integer exponent of a fixed base. It is actually not that complicated. For example, 12.568 is a floating-point number in base ten with five digits of precision: \\[ 12.568 = \\underbrace{12568}_\\text{whole number} \\times {\\underbrace{10}_\\text{base}}^{\\overbrace{-3}^\\text{integer exponent}} \\] Base ten is the most convenient base to understand how floating-point numbers are represented. But you can use any base. For example, in base five, 12.568 is represented by \\[ 12.568 = \\underbrace{22241}_\\text{whole number} \\times {\\underbrace{5}_\\text{base}}^{\\overbrace{-3}^\\text{integer exponent}}, \\] i.e. a floating-point number with five digits of precision. You can validate that this is indeed the right representation \\[ \\begin{align*} 22241 \\times 5^{-3} &amp;= (2 \\times 5^{4} + 2 \\times 5^{3} + 2 \\times 5^{2} + 4 \\times 5^{1} + 1 \\times 5^{0}) \\times 5^{-3}\\\\ &amp;= 2 \\times 5^{1} + 2 \\times 5^{0} + 2 \\times 5^{-1} + 4 \\times 5^{-2} + 1 \\times 5^{-3}\\\\ &amp;= 10 + 2 + 0,4 + 0,16 + 0.008\\\\ &amp;= 12.568. \\end{align*} \\] In base two, the representation is more complex: \\[ 12.568 = \\underbrace{1100 1001 0001 0110 1000 0111 0010 1011 0000 0010 0000 1100 0100 1001 1011 1010 011}_\\text{whole number} \\times {\\underbrace{2}_\\text{base}}^{\\overbrace{-60}^\\text{integer exponent}}, \\] but it still has the same form; a positive whole number with 64 digits of precision times the base to the power -60. Not all real numbers can be represented by a floating-point number with a predefined precision. The base and the number of digits regulate how precisely a floating point number can be represented. For example, you cannot represent 12.568 as a floating-point number with four digits of precision in base ten, five or two. The nearest whole number of 12586 with only four digits of precision is 1257. Hence, the closest we can get to 12.568 using only four digits of precision in base ten is 12.57. Not too bad. The nearest whole number of 22241 with only four digits of precision is 2224. Therefore, the closest we can get to 12.568 using only four digits of precision in base five is 12.56. A bit worse than in base ten. However, the nearest whole number of 1100100100010110100001110010101100000010000011000100100110111010011 with only four digits of precision in base 2 is 1100. This means that the closest we can get to 12.568 using only four digits of precision in base five is 12. A difference of 0.568 may not be problematic in some cases, but it can be catastrophic in others. R uses base 2 with (usually) 53 digits of precision. Hence, all floating-point numbers with more than 53 digits of precision will be represented by the nearest floating-point number with 53 digits of precision. For example, take the real number 0.3. In base two, 0.3 is represented by 0.0100110011001100110011001100… (a number with infinitely many digits of precision). The nearest floating-point number with only 53 digits of precision is 0.299999999999999988897769753748434595763683319091796875, which is the floating-point number R uses to represent 0.3. The binary representation is not perfect, but it is the best approximation R has. When you assign the value 0.3 to an object and print the object to the console afterwards, you will see that R returns 0.3: x &lt;- 0.3 x #&gt; [1] 0.3 So you may think Why did you bother me with all that talk about floating-point numbers? There is clearly no problem here! However, per default, the function print() only prints 7 significant digits when printing numeric values. getOption(&quot;digits&quot;) #&gt; [1] 7 If you increase that number to 22, you can see that 0.3 is actually represented by 0.2999999999999999888978 print(x, digits = 22) #&gt; [1] 0.2999999999999999888978 This inaccuracy is known as the floating-point error, and it is the reason why simple comparisons like the following can fail: (0.1 + 0.2) == 0.3 #&gt; [1] FALSE Instead of using == to compare two objects, use the base R function all.equal() to test if two objects are equal up to some tolerance (\\(1.5\\times 10^{-8}\\) per default). all.equal(0.1 + 0.2, 0.3) #&gt; [1] TRUE all.equal(0.1 + 0.2, 0.3, tolerance = 0) #&gt; [1] &quot;Mean relative difference: 1.850372e-16&quot; all.equal(0.1 + 0.2, 0.3, tolerance = 1e-16) #&gt; [1] &quot;Mean relative difference: 1.850372e-16&quot; all.equal(0.1 + 0.2, 0.3, tolerance = 1e-15) #&gt; [1] TRUE As all.equal() returns either TRUE or a string with the mean relative difference, you cannot use it directly in if expressions. Use isTRUE(all.equal()) instead: isTRUE(all.equal(0.1 + 0.2, 0.4)) #&gt; [1] FALSE Alternatively, you can use the dplyr function near() dplyr::near(0.1 + 0.2, 0.3) #&gt; [1] TRUE dplyr::near(0.1 + 0.2, 0.3, tol = 1e-17) #&gt; [1] FALSE 3.1.2 The ... argument Another source of mistakes often occur in connection to arguments. To illustrate the problem, let us consider a simple example. Assume we have three observations \\(-1, 5 \\text{ and }118\\), and we want to find the minimum, maximum, mean, and median in R. We know that we can use the functions min(), max(), mean(), and median() to obtain the desired numbers, so we run the following code: min(-1, 5, 118) #&gt; [1] -1 max(-1, 5, 118) #&gt; [1] 118 mean(-1, 5, 118) #&gt; [1] -1 median(-1, 5, 118) #&gt; [1] -1 The first two numbers are correct, but what is happening with the last two function calls? The problem is that the four functions take different arguments. Let us take a look at the arguments for max() first: args(max) #&gt; function (..., na.rm = FALSE) #&gt; NULL The first argument is ... (dot dot dot). The three dots represent a special argument that allows functions to take any number of arguments - besides all other specified arguments. This means ... will take all unnamed arguments passed to the function. In the example above, none of the parameters are specified by name, and max() will use \\(-1, 5 \\text{ and }118\\) to compute the maximum value. This is different in connection to the function mean(): args(mean) #&gt; function (x, ...) #&gt; NULL The first argument is x, which is followed by .... As all parameters are unnamed in the function call mean(-1, 5, 118), mean() takes the first value \\(-1\\) to compute the mean, and passes all other arguments to another function. Therefore, mean(-1, 5, 118) returns \\(-1\\). In this simple example, one solution is to store all observations in a vector and pass the vector to the functions: min(c(-1, 5, 118)) #&gt; [1] -1 max(c(-1, 5, 118)) #&gt; [1] 118 mean(c(-1, 5, 118)) #&gt; [1] 40.66667 median(c(-1, 5, 118)) #&gt; [1] 5 In more complex cases, you have to be more cautious. When a function has ... as one of its arguments, misspelled or non-existing arguments will simple be passed on and not raise an error. This increases the change of typos or wrong computations to go unnoticed. Furthermore, the argument ... is greedy, which is why you often have to name all arguments that you want to pass to the function. max(c(-1, 5, 118, NA)) #&gt; [1] NA max(c(-1, 5, 118, NA), TRUE) #&gt; [1] NA max(c(-1, 5, 118, NA), na.rm = TRUE) #&gt; [1] 118 If you want to know what other arguments ... represents, you can look in the function documentation. The function plot(), for example, takes the arguments .... When you read the function documentation (by running ?plot), you can see that ... represents other graphical parameters, and the documentation refers to the documentation for graphical parameters for details. 3.1.3 Others R has many base functions that behave differently than you may expect. One of them is sample(). sample() creates a sample of a specified size from the elements of the first argument x with or without replacement. The most common use of sample() is probably to let x be a vector: sample(1:10) #&gt; [1] 4 1 9 5 6 7 8 2 10 3 But have you ever tried to pass a single number? Or even a real number? sample(10) sample(10.1) What do you think R returns? Show me! sample(10) #&gt; [1] 4 8 9 1 5 6 7 3 10 2 sample(10.1) #&gt; [1] 9 6 1 7 5 2 4 10 3 8 Did you expect this outcome? In case you are confused, here is the reason why:. The first argument of sample() is x. x can either be a vector of one or more elements from which to choose, or a positive integer. If x has length one, is numeric and larger than 1, the sampling will take place from the sequence 1:x. On the other hand, 1:x generates a vector of real numbers; starting with 1 and increasing with 1 until the upper limit x is reached. Hence, when x = 10.1, 1:x is equal to the sequence 1,2,...,10, and sample(x) is equivalent to sample(1:10). This leads us to the next base R function with an unexpected behavior; the colon operator :. It can be used to generate regular sequences and is equivalent to seq() (if from and to are not factors). Do you know what the output of the following code will be? n &lt;- 10 1:n - 1 Show me! n &lt;- 10 1:n - 1 #&gt; [1] 0 1 2 3 4 5 6 7 8 9 The result is the sequence from 0 to 9; not 1 to 9. To understand why 1:n-1 returns 0,1,...,9, we take a look at the syntax documentation (?Syntax): The documentation shows that the colon operator : has a higher precedence than the operator -. Hence, 1:n is evaluated first, and - is evaluated afterwards (1:n-1 is equivalent to (1:n)-1). To obtain a sequence from 1 to 9, we can change the order of evaluation by using parentheses: 1:(n - 1) #&gt; [1] 1 2 3 4 5 6 7 8 9 Alternatively, we could use the function seq_len() to create a sequence that starts at 1 and with steps of 1 finishes at the number passed to the function. seq_len(n) #&gt; [1] 1 2 3 4 5 6 7 8 9 10 seq_len(n - 1) #&gt; [1] 1 2 3 4 5 6 7 8 9 However, there is one crucial difference between 1:n and seq_len(n), which we will look at in the final example! What does the colon operator return when n is equal to 0? n &lt;- 0 1:n Show me! n &lt;- 0 1:n #&gt; [1] 1 0 Did you expect the output to be 1, 0? The colon operator can also generate a sequence from from to to in steps of -1 (when to &lt; from). This behavior can be useful in general, but when : is used in a for loop it is often undesired. In situations like that, use the function seq_len() instead. When zero is passed as an argument, seq_len returns a empty integer vector (integer(0)): seq_len(0) #&gt; integer(0) seq_len() also has a sibling, seq_along(), that can be used generate a sequence that is as long as another vector. More precisely, if x is a vector of length \\(\\geq\\) 1, seq_along(x) is a shortcut for seq_len(length(x)): seq_along(5:7) #&gt; [1] 1 2 3 3.2 Useful R functions Now that you have seen common mistakes in R and learned how to avoid them, we will take a look at some useful base R functions. Some of them may be known to you, but we still recommend that you inspect the list. General ?topic : Open the documentation on a topic (typically a function or data set) in the Files pane. Equivalent to help(topic). example(topic) : Run all R code from the Examples section of R’s online help. str(object) : Compactly display the structure of an R object. Alternative to summary(). str(iris) #&gt; &#39;data.frame&#39;: 150 obs. of 5 variables: #&gt; $ Sepal.Length: num 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ... #&gt; $ Sepal.Width : num 3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ... #&gt; $ Petal.Length: num 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ... #&gt; $ Petal.Width : num 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ... #&gt; $ Species : Factor w/ 3 levels &quot;setosa&quot;,&quot;versicolor&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... ls() : List the names of the objects in the environment. rm(list = ls()) : Remove all objects from the environment. methods(generic.function) : List all available implementations of a generic function (see the next Section Data structures in R for details on methods). methods(class = [class]) : List all available methods implemented for a particular class (see the next Section Data structures in R for details on methods). do.call(fct, args) : Call a function fct with a list of arguments. (list_of_int &lt;- as.list(1:5)) #&gt; [[1]] #&gt; [1] 1 #&gt; #&gt; [[2]] #&gt; [1] 2 #&gt; #&gt; [[3]] #&gt; [1] 3 #&gt; #&gt; [[4]] #&gt; [1] 4 #&gt; #&gt; [[5]] #&gt; [1] 5 do.call(&quot;c&quot;, list_of_int) #&gt; [1] 1 2 3 4 5 do.call(&quot;rbind&quot;, list_of_int) #&gt; [,1] #&gt; [1,] 1 #&gt; [2,] 2 #&gt; [3,] 3 #&gt; [4,] 4 #&gt; [5,] 5 Sequence and vector operations seq(from, to) : Generate regular sequences (see also the previous section Common mistakes to avoid). Can be used in different ways: By specifying by(the increment of the sequence), length.out (the desired length of the sequence), or along.with (taking the length from the length of this argument). Note that seq_len(length.out) is a shortcut for seq(from = 1, to = length.out, by = 1), and that seg_along(along.with) is a shortcut for seq(from = 1, to = length(along.with), by = 1). seq(1, 10, by = 2) #&gt; [1] 1 3 5 7 9 seq(1, 100, length.out = 10) #&gt; [1] 1 12 23 34 45 56 67 78 89 100 seq(from = 1, to = 5, by = 1) #&gt; [1] 1 2 3 4 5 seq_len(5) #&gt; [1] 1 2 3 4 5 seq_along(21:24) #&gt; [1] 1 2 3 4 seq(from = 1, to = length(21:24), by = 1) #&gt; [1] 1 2 3 4 rep(x) : Replicate the values in x. Can be used in different ways: By specifying times (the number of times to repeat each element or the whole vector), length.out (the desired length of the output vector), or each (the number of times each element of x is repeated). Note that rep_len(x, length.out) is a shortcut for rep(x, length.out = length.out), and that rep.int(x, times) is a shortcut for rep(x, times = times). rep(1:4, times = 2) #&gt; [1] 1 2 3 4 1 2 3 4 rep.int(1:4, 2) #&gt; [1] 1 2 3 4 1 2 3 4 rep(1:4, times = 4:1) #&gt; [1] 1 1 1 1 2 2 2 3 3 4 rep(1:4, length.out = 6) #&gt; [1] 1 2 3 4 1 2 rep_len(1:4, 6) #&gt; [1] 1 2 3 4 1 2 rep(1:4, each = 2) #&gt; [1] 1 1 2 2 3 3 4 4 replicate(n, expr) : Repeated evaluation of an expression. Wrapper for the common use of sapply. replicate(5, rnorm(10)) #&gt; [,1] [,2] [,3] [,4] [,5] #&gt; [1,] 0.8407406 0.234535343 -0.7086898 -0.4680631 0.7313461 #&gt; [2,] -1.3067099 1.117597071 -0.1383959 -0.2577106 -1.7066608 #&gt; [3,] 0.2620064 -0.900242928 -0.2560049 -0.9049527 0.2042457 #&gt; [4,] -1.6487186 0.008642508 1.4027984 0.8067742 0.8664266 #&gt; [5,] -0.9353841 -1.236647033 1.2967483 0.7876399 0.7572688 #&gt; [6,] -1.7442622 -0.307767694 -0.8625643 1.7491127 -0.3028806 #&gt; [7,] -0.8887329 0.781024618 1.0227641 1.0123471 -0.2648647 #&gt; [8,] 0.1178956 -1.376239028 0.2537294 1.1910701 -1.0001333 #&gt; [9,] -0.1418248 0.411050077 0.4755836 -0.1848172 -0.6542619 #&gt; [10,] 0.4757799 -0.043350137 -0.1929267 0.5777101 1.0343219 If you unsure about how to use the different *apply functions in R, we recommend to take a look at this nice Q/A on grouping functions and the *apply family on Stack Overflow, along with Chapter 16 from the book R Programming for Data Science by Roger Peng about looping. sort(x) : Sort or order a vector or factor into ascending or descending order. order(x) : Get a permutation that rearranges x into ascending or descending order. In the case of ties in the first vector, values in the second are used to break the ties. order(c(1, 6, 8, 2, 2)) #&gt; [1] 1 4 5 2 3 order(c(1, 6, 8, 2, 2), c(0, 0, 0, 2, 1)) #&gt; [1] 1 5 4 2 3 rank(x) : Get the sample ranks of the values in a vector x. rank(c(1, 6, 8, 2, 2)) #&gt; [1] 1.0 4.0 5.0 2.5 2.5 rank(c(1, 6, 8, 2, 2), ties.method = &quot;first&quot;) #&gt; [1] 1 4 5 2 3 which.min(x) and which.max() : Determine the index of the minimum or maximum of a numeric vector x. unique(x) : Remove duplicated elements/rows from a vector, data frame or array like x. table(...) : Build a contingency table of the counts of each combination of factor levels. table(rep(1:4, 4:1)) #&gt; #&gt; 1 2 3 4 #&gt; 4 3 2 1 table(A = c(1, 1, 1, 2, 2), B = c(1, 2, 1, 2, 1)) #&gt; B #&gt; A 1 2 #&gt; 1 2 1 #&gt; 2 1 1 sample() : Take a sample of the specified size from the elements of x either with or without replacement. Note sample(x) is a shortcut for sample(1:x, size = x), when x has length one, is numeric and positive. sample(10) #&gt; [1] 8 10 5 2 4 1 7 3 9 6 sample(3:10, 5) #&gt; [1] 10 4 6 8 9 sample(3:10, 50, replace = TRUE) #&gt; [1] 9 3 5 4 5 3 4 5 10 7 3 4 5 7 7 8 9 8 9 8 5 6 7 9 7 5 4 8 #&gt; [29] 10 7 9 6 5 5 10 3 8 6 6 3 4 3 3 7 9 7 4 10 10 9 round(x) : Round the value in the first argument to the specified number of decimal places. Rounding to a negative number of digits means rounding to a power of ten, i.e. round(12.568, -1) #&gt; [1] 10 round(12.568, -2) #&gt; [1] 0 pmin() and pmax() : Return the regular or parallel maxima and minima of the input values. (a &lt;- 1:4) #&gt; [1] 1 2 3 4 (b &lt;- 5:2) #&gt; [1] 5 4 3 2 pmin(a, b) #&gt; [1] 1 2 3 2 pmax(a, b) #&gt; [1] 5 4 3 4 outer(X, Y, fun) : Compute the outer product of the arrays X and Y using the function fun. The result is an array of dimension c(dim(X), dim(Y)) where each element \\(A_{xy}\\) is equal to \\(fun(X_x, Y_y)\\). outer(1:4, 1:3, &quot;+&quot;) #&gt; [,1] [,2] [,3] #&gt; [1,] 2 3 4 #&gt; [2,] 3 4 5 #&gt; [3,] 4 5 6 #&gt; [4,] 5 6 7 expand.grid() : Create a data frame from all combinations of the supplied vectors or factors. expand.grid(a, b) #&gt; Var1 Var2 #&gt; 1 1 5 #&gt; 2 2 5 #&gt; 3 3 5 #&gt; 4 4 5 #&gt; 5 1 4 #&gt; 6 2 4 #&gt; 7 3 4 #&gt; 8 4 4 #&gt; 9 1 3 #&gt; 10 2 3 #&gt; 11 3 3 #&gt; 12 4 3 #&gt; 13 1 2 #&gt; 14 2 2 #&gt; 15 3 2 #&gt; 16 4 2 match() : Return a vector of positions of (first) matches of the first argument in the second argument (y &lt;- sample(20:25, 10, replace = TRUE)) #&gt; [1] 20 21 25 23 20 24 25 23 21 22 match(y, 20:25) #&gt; [1] 1 2 6 4 1 5 6 4 2 3 %in% : Return a logical vector indicating if there is a match or not for the left operand. y %in% 20:22 #&gt; [1] TRUE TRUE FALSE FALSE TRUE FALSE FALSE FALSE TRUE TRUE intersect(x, y) : Perform set intersection (\\(x \\cap y\\)). intersect(c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;), c(&quot;c&quot;, &quot;d&quot;, &quot;e&quot;)) #&gt; [1] &quot;c&quot; &quot;d&quot; union(x, y) : Perform set union (\\(x \\cup y\\)). union(c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;), c(&quot;c&quot;, &quot;d&quot;, &quot;e&quot;)) #&gt; [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; &quot;d&quot; &quot;e&quot; setdiff(x, y) : Perform set asymmetric difference (\\(x \\setminus y\\)). setdiff(c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;), c(&quot;c&quot;, &quot;d&quot;, &quot;e&quot;)) #&gt; [1] &quot;a&quot; &quot;b&quot; Character operations paste() : Concatenate vectors after converting to character. To separate the different terms with a special character string, specify the argument sep. To separate the results with a character string, specify the argument collapse. Note that paste0(...) is equivalent to paste(..., sep = \"\"). paste(&quot;I&quot;, &quot;am&quot;, &quot;me&quot;) #&gt; [1] &quot;I am me&quot; paste0(&quot;I&quot;, &quot;am&quot;, &quot;me&quot;) #&gt; [1] &quot;Iamme&quot; paste0(&quot;PC&quot;, 1:5) #&gt; [1] &quot;PC1&quot; &quot;PC2&quot; &quot;PC3&quot; &quot;PC4&quot; &quot;PC5&quot; paste0(&quot;PC&quot;, 1:5, collapse = &quot; + &quot;) #&gt; [1] &quot;PC1 + PC2 + PC3 + PC4 + PC5&quot; list.files(path, pattern) : Produce a character vector of the names if files or directories in the names directory. If pattern is specified, only file names with match the regular expression defined in pattern will be returned. list.files(pattern = &quot;\\\\.Rmd$&quot;, full.names = TRUE) #&gt; [1] &quot;./good-practices.Rmd&quot; &quot;./index.Rmd&quot; #&gt; [3] &quot;./intro.Rmd&quot; &quot;./packages.Rmd&quot; #&gt; [5] &quot;./performance.Rmd&quot; &quot;./presentation_project.Rmd&quot; #&gt; [7] &quot;./r-markdown.Rmd&quot; &quot;./r-programming.Rmd&quot; #&gt; [9] &quot;./shiny.Rmd&quot; &quot;./tidyverse.Rmd&quot; sub(pattern, replacement, x) : Perform replacement of the first match sub(&quot;James&quot;, &quot;Mr.&quot;, &quot;James Bond&quot;) #&gt; [1] &quot;Mr. Bond&quot; split(x, f) : Divide the data in the vector x into the groups defined by f. split(1:12, rep(letters[1:3], 4)) #&gt; $a #&gt; [1] 1 4 7 10 #&gt; #&gt; $b #&gt; [1] 2 5 8 11 #&gt; #&gt; $c #&gt; [1] 3 6 9 12 Logical operators | : Logical OR. Performs element-wise comparisons in much the same was as arithmetic operators. TRUE | stop(&quot;Both conditions are evaluated&quot;) #&gt; Error in eval(expr, envir, enclos): Both conditions are evaluated || : Logical OR. Evaluation is performed left to right, proceeding only until the result is determined. Hence, if the first condition is TRUE, the second condition is not evaluated. TRUE || stop(&quot;The first condiciton is TRUE, therefore the second condition is not evaluated...&quot;) #&gt; [1] TRUE FALSE || stop(&quot;The first condiciton is FALSE, therefore the second condition is evaluated...&quot;) #&gt; Error in eval(expr, envir, enclos): The first condiciton is FALSE, therefore the second condition is evaluated... Important note: || can only be used with vectors holding one element. Using vectors of more than one element in || will return an error in newer R versions. However, in R versions &lt; 4.3.0, using vectors of more than one element in || will simply evaluate the first element and not raise a warning! c(TRUE, FALSE, TRUE, TRUE) || c(FALSE, TRUE, TRUE, FALSE) #&gt; Error in c(TRUE, FALSE, TRUE, TRUE) || c(FALSE, TRUE, TRUE, FALSE): &#39;length = 4&#39; in coercion to &#39;logical(1)&#39; &amp; : Logical AND. Performs element-wise comparisons in much the same was as arithmetic operators. c(TRUE, FALSE, TRUE, TRUE) &amp; c(FALSE, TRUE, TRUE, FALSE) #&gt; [1] FALSE FALSE TRUE FALSE &amp;&amp; : Logical AND. Evaluation is performed left to right, proceeding only until the result is determined. Hence, if the first condition is FALSE, the second condition is not evaluated. FALSE &amp;&amp; stop(&quot;The first condiciton is FALSE, therefore the second condition is not evaluated...&quot;) #&gt; [1] FALSE TRUE &amp;&amp; stop(&quot;The first condiciton is TRUE, therefore the second condition is evaluated...&quot;) #&gt; Error in eval(expr, envir, enclos): The first condiciton is TRUE, therefore the second condition is evaluated... Important note: &amp;&amp; can only be used with vectors holding one element. Using vectors of more than one element in &amp;&amp; will return an error in newer R versions. However, in R versions &lt; 4.3.0, using vectors of more than one element in &amp;&amp; will simply evaluate the first element and not raise a warning! c(TRUE, FALSE, TRUE, TRUE) &amp;&amp; c(FALSE, TRUE, TRUE, FALSE) #&gt; Error in c(TRUE, FALSE, TRUE, TRUE) &amp;&amp; c(FALSE, TRUE, TRUE, FALSE): &#39;length = 4&#39; in coercion to &#39;logical(1)&#39; ifelse(test, yes, no) : Conditional element selection. yes will be evaluated if and only if any element of test is TRUE, and analogously for no. round(x &lt;- rnorm(10), digits = 5) #&gt; [1] -2.12443 1.26048 -0.39612 -0.58123 0.68140 -0.89008 0.44292 1.11721 -1.26107 #&gt; [10] 0.39992 ifelse(x &gt; 0, x, -x) #&gt; [1] 2.1244291 1.2604793 0.3961162 0.5812299 0.6813982 0.8900768 0.4429189 1.1172113 #&gt; [9] 1.2610740 0.3999177 ifelse() can be used to handle special cases in a vectorized way, or it can be used to construct a vector by doing element-wise comparisons of two vectors. ifelse() is NOT a shortcut for an if-else statement! ifelse() always returns a vector of the same length and attributes as the condition. Hence, if the length of the input vector is one, ifelse() only returns the first element of the returning vector: ifelse(FALSE, 0, 1:5) #&gt; [1] 1 If the input is of type integer, ifelse() returns a vector of type integer: ifelse(1, Sys.Date(), 0) #&gt; [1] 19956 If you want a more compact way of writing a standard if-else statement, you can use the function `if()`: `if`(FALSE, 0, 1:5) #&gt; [1] 1 2 3 4 5 `if`(TRUE, Sys.Date(), 1:5) #&gt; [1] &quot;2024-08-21&quot; In simple cases, however, the standard if-else statement can also be written very compact: if (FALSE) 0 else 1:5 #&gt; [1] 1 2 3 4 5 To learn more about the behavior of ifelse() and why it is easily misunderstood, read Florian’s blog post On the ifelse function. You can find many other useful base R functions in this GitHub repository or in this french documentation on cran. Useful non-base R functions The following functions are not part of base R, but they are still very useful: skimr::skim(data.frame) : Quickly provide a broad overview of a data frame. Alternative to summary(). skimr::skim(iris) Table 3.1: Data summary Name iris Number of rows 150 Number of columns 5 _______________________ Column type frequency: factor 1 numeric 4 ________________________ Group variables None Variable type: factor skim_variable n_missing complete_rate ordered n_unique top_counts Species 0 1 FALSE 3 set: 50, ver: 50, vir: 50 Variable type: numeric skim_variable n_missing complete_rate mean sd p0 p25 p50 p75 p100 hist Sepal.Length 0 1 5.84 0.83 4.3 5.1 5.80 6.4 7.9 ▆▇▇▅▂ Sepal.Width 0 1 3.06 0.44 2.0 2.8 3.00 3.3 4.4 ▁▆▇▂▁ Petal.Length 0 1 3.76 1.77 1.0 1.6 4.35 5.1 6.9 ▇▁▆▇▂ Petal.Width 0 1 1.20 0.76 0.1 0.3 1.30 1.8 2.5 ▇▁▇▅▃ glue::glue() : Format and interpolate a string. Expressions enclosed by braces are evaluated as R code. me &lt;- &quot;Florian&quot; glue::glue(&quot;I am {me}&quot;) #&gt; I am Florian gtools::mixedsort(x) : Sort character strings containing embedded numbers so that the numbers are numerically sorted rather than sorted by character value. sort(c(&quot;a1&quot;, &quot;a2&quot;, &quot;a10&quot;)) #&gt; [1] &quot;a1&quot; &quot;a10&quot; &quot;a2&quot; gtools::mixedsort(c(&quot;a1&quot;, &quot;a2&quot;, &quot;a10&quot;)) #&gt; [1] &quot;a1&quot; &quot;a2&quot; &quot;a10&quot; dplyr::case_when() : Vectorize multiple ifelse() statements. Each case is evaluated sequentially and the first match for each element determines the corresponding value in the output vector. round(x &lt;- c(runif(20, min = 15.0, max = 50.0), NA), digits = 4) #&gt; [1] 49.5439 29.6140 38.7192 39.3617 25.9959 42.3621 19.1224 27.7902 21.2610 46.4565 #&gt; [11] 41.0991 37.4642 34.3132 31.4283 39.3534 49.8420 48.0150 45.7231 15.7020 44.8376 #&gt; [21] NA dplyr::case_when(x &lt; 16.0 ~ &quot;Severely Underweight&quot;, x &lt;= 18.4 ~ &quot;Underweight&quot;, x &lt;= 24.9 ~ &quot;Normal&quot;, x &lt;= 29.9 ~ &quot;Overweight&quot;, x &lt;= 34.9 ~ &quot;Moderate Obese&quot;, x &lt;= 39.9 ~ &quot;Severely Obese&quot;, x &gt;= 40.0 ~ &quot;Morbidly Obese&quot;, .default = as.character(NA) ) #&gt; [1] &quot;Morbidly Obese&quot; &quot;Overweight&quot; &quot;Severely Obese&quot; #&gt; [4] &quot;Severely Obese&quot; &quot;Overweight&quot; &quot;Morbidly Obese&quot; #&gt; [7] &quot;Normal&quot; &quot;Overweight&quot; &quot;Normal&quot; #&gt; [10] &quot;Morbidly Obese&quot; &quot;Morbidly Obese&quot; &quot;Severely Obese&quot; #&gt; [13] &quot;Moderate Obese&quot; &quot;Moderate Obese&quot; &quot;Severely Obese&quot; #&gt; [16] &quot;Morbidly Obese&quot; &quot;Morbidly Obese&quot; &quot;Morbidly Obese&quot; #&gt; [19] &quot;Severely Underweight&quot; &quot;Morbidly Obese&quot; NA Exercises Use sample(), rep_len() and split() to make a function that randomly splits some indices in a list of K groups of indices (like for cross-validation). [Which are the special cases that you should consider?] advr38pkg::split_ind(1:40, 3) #&gt; $`1` #&gt; [1] 5 9 11 15 17 19 22 26 28 30 35 37 38 39 #&gt; #&gt; $`2` #&gt; [1] 3 4 6 7 8 14 18 20 23 24 25 31 33 #&gt; #&gt; $`3` #&gt; [1] 1 2 10 12 13 16 21 27 29 32 34 36 40 Use replicate() and sample() to get a 95% confidence interval (using bootstrapping) for the mean of the following vector: set.seed(1) (x &lt;- rnorm(10)) #&gt; [1] -0.6264538 0.1836433 -0.8356286 1.5952808 0.3295078 -0.8204684 0.4874291 #&gt; [8] 0.7383247 0.5757814 -0.3053884 mean(x) #&gt; [1] 0.1322028 Expected output (approximately): #&gt; 2.5% 97.5% #&gt; -0.3145143 0.5998608 Use match() and some special accessor to add a column “my_val” to the data my_mtcars by putting the corresponding value of the column specified in “my_col”. [Can your solution be used for any number of column names?] my_mtcars &lt;- mtcars[c(&quot;mpg&quot;, &quot;hp&quot;)] my_mtcars$my_col &lt;- sample(c(&quot;mpg&quot;, &quot;hp&quot;), size = nrow(my_mtcars), replace = TRUE) head(my_mtcars) #&gt; mpg hp my_col #&gt; Mazda RX4 21.0 110 mpg #&gt; Mazda RX4 Wag 21.0 110 mpg #&gt; Datsun 710 22.8 93 hp #&gt; Hornet 4 Drive 21.4 110 hp #&gt; Hornet Sportabout 18.7 175 mpg #&gt; Valiant 18.1 105 hp Expected result (head): #&gt; mpg hp my_col my_val #&gt; Mazda RX4 21.0 110 mpg 21.0 #&gt; Mazda RX4 Wag 21.0 110 mpg 21.0 #&gt; Datsun 710 22.8 93 hp 93 #&gt; Hornet 4 Drive 21.4 110 hp 110 #&gt; Hornet Sportabout 18.7 175 mpg 18.7 #&gt; Valiant 18.1 105 hp 105 In the following data frame (recall that a data frame is also a list), for the first 3 columns, replace letters by corresponding numbers based on the code: df &lt;- data.frame( id1 = c(&quot;a&quot;, &quot;f&quot;, &quot;a&quot;), id2 = c(&quot;b&quot;, &quot;e&quot;, &quot;e&quot;), id3 = c(&quot;c&quot;, &quot;d&quot;, &quot;f&quot;), inter = c(7.343, 2.454, 3.234), stringsAsFactors = FALSE ) df #&gt; id1 id2 id3 inter #&gt; 1 a b c 7.343 #&gt; 2 f e d 2.454 #&gt; 3 a e f 3.234 (code &lt;- setNames(1:6, letters[1:6])) #&gt; a b c d e f #&gt; 1 2 3 4 5 6 Expected result: #&gt; id1 id2 id3 inter #&gt; 1 1 2 3 7.343 #&gt; 2 6 5 4 2.454 #&gt; 3 1 5 6 3.234 3.3 Data structures in R R provides a number of data structures, i.e. particular ways of organizing data to make their use more effective. These data structures are referred to as objects. In this chapter, we will take a look at the most frequently used objects in R. 3.3.1 Types All R objects have a type. R supports more than 20 different types (see all of them here), but we will only focus on four of six basic (atomic) vector types in this section, namely logical, integer, double (often called numeric), and character. Atomic vectors represent the most simple data structure in R. They are one dimensional and homogeneous, which means that all contents must be of the same type. Single numbers, such as 12.568, and strings, such as Hello world, are vectors; just of length 1. The fact that all components of an atomic vectors must be of the same type means that they are often coerced to different types during operations. R objects are coerced according to the following precedence: logical : Logical vectors have the lowest precedence. Whenever a logical vector is combined with a vector of another type, the logical vector will be turned into the other type. integer : Integer vectors have the second lowest precedence. Combining an integer vector with a vector of type double or character, will result in a vector of type double or character, respectively. double : Vectors of type double have the second highest precedence. They will only change type when they are combined with a vector of type character. character : Character vectors are never coerced. When you combine two or more vectors, one of them being of type character, the resulting vector will be of type character as well. In most situations, you do not have to worry about coercion, as R usually coerces the relevant objects automatically. However, some functions may not be able to coerce objects (due to the precedence). In those cases, R returns an error. Let us consider some examples. We define four vectors, one of each type: (logi_vec &lt;- FALSE) #&gt; [1] FALSE typeof(logi_vec) #&gt; [1] &quot;logical&quot; (int_vec &lt;- 1:10) #&gt; [1] 1 2 3 4 5 6 7 8 9 10 typeof(int_vec) #&gt; [1] &quot;integer&quot; (dbl_vec &lt;- c(2.5, 12.568)) #&gt; [1] 2.500 12.568 typeof(dbl_vec) #&gt; [1] &quot;double&quot; (char_vec &lt;- c(&quot;abc&quot;)) #&gt; [1] &quot;abc&quot; typeof(char_vec) #&gt; [1] &quot;character&quot; What is the type of each of the resulting vectors below? c(logi_vec, int_vec) c(int_vec, dbl_vec) c(logi_vec, char_vec) Show me! typeof(c(logi_vec, int_vec)) #&gt; [1] &quot;integer&quot; typeof(c(int_vec, dbl_vec)) #&gt; [1] &quot;double&quot; typeof(c(logi_vec, char_vec)) #&gt; [1] &quot;character&quot; Line 1: The logical vector logi_vec is coerced to an integer vector (FALSE is coerced to 0), and the resulting vector is of type integer. Line 3: The integer vector int_vec is coerced to a double vector, which is why c(int_vec, dbl_vec) is of type double. Line 5: The logical vector logi_vec is coerced to a character vector, and the result is a vector of type character. What is the result of the following operations? Is R able to coerce the objects into the required type, or will it return an error? logi_vec &lt; char_vec min(int_vec, dbl_vec) logi_vec + char_vec Show me! logi_vec &lt; char_vec #&gt; [1] FALSE min(int_vec, dbl_vec) #&gt; [1] 1 logi_vec + char_vec #&gt; Error in logi_vec + char_vec: non-numeric argument to binary operator Line 1: The logical vector logi_vec is coerced to a character vector. The operator &lt; is able to compare strings (using lexicographic orders), and as F comes after a in the alphabet, the comparison returns FALSE. Line 3: The integer vector int_vec is coerced to a double vector, and min(int_vec, dbl_vec) returns 1. Line 5: The logical vector logi_vec can be coerced to a character vector, but char_vec cannot be coreced to a integer or double vector. As + is only implemented for numeric or complex vectors, R returns an error. Exercises Why is the default missing value, NA, a logical vector? How can you use the automatic type coercion to convert this boolean matrix to a numeric one (with 0s and 1s)? (mat &lt;- matrix(sample(c(TRUE, FALSE), 12, replace = TRUE), nrow = 3)) #&gt; [,1] [,2] [,3] [,4] #&gt; [1,] FALSE TRUE TRUE TRUE #&gt; [2,] FALSE FALSE FALSE FALSE #&gt; [3,] FALSE TRUE TRUE FALSE What do you need to change in the code above to obtain an integer matrix immediately? 3.3.2 Objects and attributes In the previous section, we have introduced the most simple data structure in R: atomic vectors. Recall that atomic vectors are one dimensional and homogeneous, which means that all components must be of the same base type (logical, integer, double, or character). R provides another one-dimensional data structure; generic vectors, better known as lists. The important difference between atomic vectors and generic vectors/lists is that lists can contain different types, i.e. lists are heterogeneous. All vectors (i.e. atomic and generic) can have one or more attributes. Attributes are name-value pairs that attach metadata to an object. They can be accessed and modified with attributes() (to get a list of all attributes) and attr() (to access a particular component). By adding specific attributes to vectors, we obtain other important data structures like matrices, arrays, and data frames. Two-dimensional matrices and multi-dimensional arrays are obtained from atomic vectors by adding the dimensions attribute dim: # Defining an atomic vector (vec &lt;- 1:12) #&gt; [1] 1 2 3 4 5 6 7 8 9 10 11 12 attributes(vec) #&gt; NULL # Modifying the attribute &#39;dim&#39; dim(vec) &lt;- c(3, 4) vec #&gt; [,1] [,2] [,3] [,4] #&gt; [1,] 1 4 7 10 #&gt; [2,] 2 5 8 11 #&gt; [3,] 3 6 9 12 attributes(vec) #&gt; $dim #&gt; [1] 3 4 class(vec) #&gt; [1] &quot;matrix&quot; &quot;array&quot; # Modifying the attribute &#39;dim&#39; once more dim(vec) &lt;- c(3, 2, 2) vec #&gt; , , 1 #&gt; #&gt; [,1] [,2] #&gt; [1,] 1 4 #&gt; [2,] 2 5 #&gt; [3,] 3 6 #&gt; #&gt; , , 2 #&gt; #&gt; [,1] [,2] #&gt; [1,] 7 10 #&gt; [2,] 8 11 #&gt; [3,] 9 12 attributes(vec) #&gt; $dim #&gt; [1] 3 2 2 class(vec) #&gt; [1] &quot;array&quot; Instead of modifying the attribute using the function dim(), you can simple use the functions matrix() or array(): # Defining a matrix (mat &lt;- matrix(1:12, ncol = 4, nrow = 3)) #&gt; [,1] [,2] [,3] [,4] #&gt; [1,] 1 4 7 10 #&gt; [2,] 2 5 8 11 #&gt; [3,] 3 6 9 12 attributes(mat) #&gt; $dim #&gt; [1] 3 4 dim(mat) #&gt; [1] 3 4 # Defining a 3-dimensional array (arry &lt;- array(1:12, c(3, 2, 2))) #&gt; , , 1 #&gt; #&gt; [,1] [,2] #&gt; [1,] 1 4 #&gt; [2,] 2 5 #&gt; [3,] 3 6 #&gt; #&gt; , , 2 #&gt; #&gt; [,1] [,2] #&gt; [1,] 7 10 #&gt; [2,] 8 11 #&gt; [3,] 9 12 attributes(arry) #&gt; $dim #&gt; [1] 3 2 2 dim(arry) #&gt; [1] 3 2 2 Data frames are similar to matrices in that they are two-dimensional structures. However, data frames are based on generic vectors, i.e. a data frame is a list of equal-length vectors. a &lt;- c(1, 2, 3) b &lt;- c(12.568, 12.569, 12.57) y &lt;- c(TRUE, FALSE, TRUE) z &lt;- c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;) (df &lt;- data.frame(a, b, y, z)) #&gt; a b y z #&gt; 1 1 12.568 TRUE a #&gt; 2 2 12.569 FALSE b #&gt; 3 3 12.570 TRUE c Because of their definition, data frames share properties of both the matrix and the list. For instance, the dimension of a data frame correspond to the dimension of a matrix (number of observations, i.e. the length of the atomic vectors, times the number of variables, i.e. the length of the list). But the length of a data frame is equal to the length of the list; not the total number of observations as for matrices: dim(df) #&gt; [1] 3 4 length(df) #&gt; [1] 4 Another important difference between matrices and data frames is that, per default, data frames have three attributes, whereas matrices only have one: attributes(df) #&gt; $names #&gt; [1] &quot;a&quot; &quot;b&quot; &quot;y&quot; &quot;z&quot; #&gt; #&gt; $class #&gt; [1] &quot;data.frame&quot; #&gt; #&gt; $row.names #&gt; [1] 1 2 3 These attributes are names, labelling the variables class, a vector of character strings giving the names of the classes which the object inherits from row.names, labelling the cases The names attribute labels the individual elements of a vector or list. You can name a vector in three ways: when creating it (a &lt;- c(a = 1, b = 2, c = 3)) #&gt; a b c #&gt; 1 2 3 by modifying an existing vector’s names attribute using names&lt;- b &lt;- 1:3 names(b) &lt;- c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;) b #&gt; a b c #&gt; 1 2 3 or by creating a modified copy of a vector using setNames setNames(1:3, c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;)) #&gt; a b c #&gt; 1 2 3 The class attribute helps R to apply the correct function to an object. When a generic function (such as summary()) is applied to an object with a class attribute (for example data.frame) R tries to find the class-specific function (e.g. summary.data.frame()). A class-specific function is called method. If the class-specific function is available, it is applied to the object. If the class name does not produce a suitable function, the default function (e.g. summary.default()) is used. Please note that an object can have many classes. In that case, R will go through all classes, one at a time, and use the first method that is available. For example, when applying a function fct() on the object tbl specified below, R will look for the function fct.tbl_df() first. If the function exists, it will be applied. If not, R will look for the function fct.tbl(). If fct.tbl() is defined, it will be applied to tbl. Otherwise, R will look for the function fct.data.frame(). If the function exists, it will be applied. If not, R will apply fct.default(). tbl &lt;- tibble::tibble(first = &quot;James&quot;, last = &quot;Bond&quot;) class(tbl) #&gt; [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; If you want to find all methods that can be used on an object of a particular class, use methods(class = [class]), i.e. methods(class = &quot;data.frame&quot;) #&gt; [1] $&lt;- [ [[ [[&lt;- [&lt;- aggregate #&gt; [7] anyDuplicated anyNA as.data.frame as.list as.matrix as.vector #&gt; [13] by cbind coerce dim dimnames dimnames&lt;- #&gt; [19] droplevels duplicated edit filter format formula #&gt; [25] head initialize intersect is.na Math merge #&gt; [31] na.exclude na.omit Ops plot print prompt #&gt; [37] rbind row.names row.names&lt;- rowsum setdiff setequal #&gt; [43] show slotsFromS3 sort_by split split&lt;- stack #&gt; [49] str subset summary Summary t tail #&gt; [55] transform type.convert union unique unstack within #&gt; [61] xtfrm #&gt; see &#39;?methods&#39; for accessing help and source code The row.names attribute is similar to the names attribute, but instead of labelling the variables it labels the observations/cases/rows. Besides dim, names, class, and row.names, R also provides some other attributes that we will not discuss here. We want to note, however, that you can define your own attributes using the function structure: x &lt;- structure(1:10, my_own_attr = &quot;Hello world!&quot;) attributes(x) #&gt; $my_own_attr #&gt; [1] &quot;Hello world!&quot; If you simply want to define your own class, however, it is easier to use the function class() directly on the object: (agent007 &lt;- list(first = &quot;James&quot;, last = &quot;Bond&quot;)) #&gt; $first #&gt; [1] &quot;James&quot; #&gt; #&gt; $last #&gt; [1] &quot;Bond&quot; class(agent007) &lt;- &quot;Person&quot; attr(agent007, &quot;class&quot;) #&gt; [1] &quot;Person&quot; Once you have created your own class, you can define class-specific functions as described above. A class-specific function is simply a function called &lt;method_name&gt;.&lt;class_name&gt;() For the object agent007 of class Person, we may want to define a special printfunction: print.Person &lt;- function(x) { print(glue::glue(&quot;My name is {x$last}, {x$first} {x$last}.&quot;)) invisible(x) } agent007 #&gt; My name is Bond, James Bond. Once the method has been defined, each object of class Person will be printed in that way (unless we specifically ask R to use the default method): (me &lt;- list(first = &quot;Florian&quot;, last = &quot;Privé&quot;)) #&gt; $first #&gt; [1] &quot;Florian&quot; #&gt; #&gt; $last #&gt; [1] &quot;Privé&quot; class(me) &lt;- &quot;Person&quot; me #&gt; My name is Privé, Florian Privé. print.default(me) #&gt; $first #&gt; [1] &quot;Florian&quot; #&gt; #&gt; $last #&gt; [1] &quot;Privé&quot; #&gt; #&gt; attr(,&quot;class&quot;) #&gt; [1] &quot;Person&quot; In most cases, you should not simply remove an attribute from an object, unless you know what you are doing. Otherwise you may end up with very strange results. For example, if you remove the attribute levels from a factor, R will no longer be able to perform simple operations on that factor: (x &lt;- sample(c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;), 12, replace = TRUE)) #&gt; [1] &quot;b&quot; &quot;b&quot; &quot;a&quot; &quot;c&quot; &quot;a&quot; &quot;c&quot; &quot;b&quot; &quot;a&quot; &quot;b&quot; &quot;b&quot; &quot;c&quot; &quot;b&quot; y &lt;- factor(x) attributes(y) #&gt; $levels #&gt; [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; #&gt; #&gt; $class #&gt; [1] &quot;factor&quot; attr(y, &quot;levels&quot;) &lt;- NULL y #&gt; Error in as.character.factor(x): malformed factor And if you remove the attribute class, the factor is turned into an atomic vector y &lt;- factor(x) attributes(y) #&gt; $levels #&gt; [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; #&gt; #&gt; $class #&gt; [1] &quot;factor&quot; unclass(y) #&gt; [1] 2 2 1 3 1 3 2 1 2 2 3 2 #&gt; attr(,&quot;levels&quot;) #&gt; [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; If you remove the only attribute (class) from a date vector, the result is a numeric vector representing the number of days since 1970-01-01 (today &lt;- Sys.Date()) #&gt; [1] &quot;2024-08-21&quot; attributes(today) #&gt; $class #&gt; [1] &quot;Date&quot; unclass(today) #&gt; [1] 19956 Exercise Define a simple function that takes two arguments (first_name and last_name) and that returns an object of class “Person”. 3.3.3 Accessors In the previous section, we have seen how we can adding attributes to vectors in order to obtain other important data structures like matrices, arrays, and data frames. Furthermore, we mentioned that two-dimensional matrices and multi-dimensional arrays are based on atomic vectors, while data frames are obtained from generic vectors/lists. We will now see that the choice of vector type (atomic vs. generic) has an effect on the accessibility of elements. For two-dimensional matrices, multi-dimensional arrays and data frames, elements can be accessed in different ways. Data frames can be subsetted like a one-dimensional structure (where it behaves like a list), or a two-dimensional structure (where it behaves like a matrix). The [ accessor can be used on vectors, matrices, arrays, lists and data frames to extract or replace subsets of the data with the same class. (x &lt;- 1:5) #&gt; [1] 1 2 3 4 5 x[2:3] #&gt; [1] 2 3 x[2:8] #&gt; [1] 2 3 4 5 NA NA NA (y &lt;- matrix(1:12, nrow = 3)) #&gt; [,1] [,2] [,3] [,4] #&gt; [1,] 1 4 7 10 #&gt; [2,] 2 5 8 11 #&gt; [3,] 3 6 9 12 y[4:9] #&gt; [1] 4 5 6 7 8 9 (l &lt;- list(a = 2:3, b = &quot;toto&quot;, c = runif(10))) #&gt; $a #&gt; [1] 2 3 #&gt; #&gt; $b #&gt; [1] &quot;toto&quot; #&gt; #&gt; $c #&gt; [1] 0.664580411 0.917853037 0.131289158 0.880099960 0.713364926 0.481320657 0.558787325 #&gt; [8] 0.003776938 0.255363885 0.991235470 l[2:3] #&gt; $b #&gt; [1] &quot;toto&quot; #&gt; #&gt; $c #&gt; [1] 0.664580411 0.917853037 0.131289158 0.880099960 0.713364926 0.481320657 0.558787325 #&gt; [8] 0.003776938 0.255363885 0.991235470 What does with the same class mean? It means that the class of the resulting subset is the same as the object that was subsetted with [. That means, when you subset a vector with the [ accessor, the subset is a vector as well. When you subset a list with the [ accessor, the result is a list: Even if you only select a single entry of the list. The index object can be numeric, logical, character, or empty: x[c(FALSE, TRUE, FALSE, TRUE, FALSE)] #&gt; [1] 2 4 x[c(FALSE, TRUE)] #&gt; [1] 2 4 y[] #&gt; [,1] [,2] [,3] [,4] #&gt; [1,] 1 4 7 10 #&gt; [2,] 2 5 8 11 #&gt; [3,] 3 6 9 12 l[c(&quot;a&quot;, &quot;c&quot;)] #&gt; $a #&gt; [1] 2 3 #&gt; #&gt; $c #&gt; [1] 0.664580411 0.917853037 0.131289158 0.880099960 0.713364926 0.481320657 0.558787325 #&gt; [8] 0.003776938 0.255363885 0.991235470 l[c(FALSE, TRUE)] #&gt; $b #&gt; [1] &quot;toto&quot; Besides using a single vector to subset matrices, arrays and data frames, you can also specify several indices to [ to obtain two-dimensional subsets. An empty index indicates that all entries in that dimension are selected: y[2:3] #&gt; [1] 2 3 y[2:3, ] #&gt; [,1] [,2] [,3] [,4] #&gt; [1,] 2 5 8 11 #&gt; [2,] 3 6 9 12 y[, 2:3] #&gt; [,1] [,2] #&gt; [1,] 4 7 #&gt; [2,] 5 8 #&gt; [3,] 6 9 y[2, 3] #&gt; [1] 8 Matrices and arrays can also be indexed via a numeric matrix with one column for each dimension. Each row of the index matrix then selects a single element of the array: two_col_ind &lt;- cbind(c(1, 3, 2), c(1, 4, 2)) y[two_col_ind] #&gt; [1] 1 12 5 The [[ and the $ accessor are both operators to access or replace a single element. However, while [[ can be used on vectors, matrices, arrays, lists and data frames, the $ accessor does only work on lists and data frames. x[[3]] #&gt; [1] 3 l[[2]] #&gt; [1] &quot;toto&quot; l[[&quot;c&quot;]] #&gt; [1] 0.664580411 0.917853037 0.131289158 0.880099960 0.713364926 0.481320657 0.558787325 #&gt; [8] 0.003776938 0.255363885 0.991235470 l$c #&gt; [1] 0.664580411 0.917853037 0.131289158 0.880099960 0.713364926 0.481320657 0.558787325 #&gt; [8] 0.003776938 0.255363885 0.991235470 names(x) &lt;- letters[1:5] x #&gt; a b c d e #&gt; 1 2 3 4 5 x$e #&gt; Error in x$e: $ operator is invalid for atomic vectors You can see that for the atomic vector x, x[3] and x[[3]] result in the same output; a vector of length one. But for the list l, the [ accessor returns a list with one entry, while [[ returns a matrix. You can think of a list as a pepper pot, each entry of the list being a sachet of pepper. The [ accessor extracts the desired sachets, but they are still contained within the pot. The [[ accessor takes the desired sachets out of the pot. Figure 3.1: Indexing lists in R. [Source: https://goo.gl/8UkcHq] Besides the fact that the $ accessor cannot be used on atomic vectors, matrices or arrays, the main difference between [[ and $ is that $ does not allow computed indices: l[[2 - 1]] l$(2-1) #&gt; Error: &lt;text&gt;:2:3: unexpected &#39;(&#39; #&gt; 1: l[[2 - 1]] #&gt; 2: l$( #&gt; ^ Before we move on to some exercises, we have two more comments. Per default, the [[ accessor only extracts columns if their column names match one of the strings provided in a character vector exactly. That means, if you want to extract a list entry named aaakv using [[a]], the result will be NULL: names(l) &lt;- c(&quot;aaakv&quot;, &quot;b&quot;, &quot;c&quot;) l #&gt; $aaakv #&gt; [1] 2 3 #&gt; #&gt; $b #&gt; [1] &quot;toto&quot; #&gt; #&gt; $c #&gt; [1] 0.664580411 0.917853037 0.131289158 0.880099960 0.713364926 0.481320657 0.558787325 #&gt; [8] 0.003776938 0.255363885 0.991235470 l$a #&gt; [1] 2 3 l[[&quot;a&quot;]] #&gt; NULL To allow for partial matching, use exact = FALSE: l[[&quot;a&quot;, exact = FALSE]] #&gt; [1] 2 3 Per default, the [ accessor coerces the result to the lowest possible dimension. For example, if you extract a single row from a matrix using [, the result will be a vector: y #&gt; [,1] [,2] [,3] [,4] #&gt; [1,] 1 4 7 10 #&gt; [2,] 2 5 8 11 #&gt; [3,] 3 6 9 12 y[1, ] #&gt; [1] 1 4 7 10 To change this behavior, set drop = FALSE y[1, , drop = FALSE] #&gt; [,1] [,2] [,3] [,4] #&gt; [1,] 1 4 7 10 Exercises In which order are matrix elements stored? Use the dimension attribute to make a function that computes the sum of every n successive elements of a vector. Ex: 1 2 3 4 5 6 7 8 9 10 -&gt; expected outcome: 3 7 11 15 19 [Which are the special cases that you should consider?] Compute the means of every numeric column of the dataset iris. Expected result: #&gt; Sepal.Length Sepal.Width Petal.Length Petal.Width #&gt; 5.843333 3.057333 3.758000 1.199333 Convert the following matrix to a vector by using this replacement rule for rows: (0, 0) -&gt; 0 (0, 1) -&gt; 1 (1, 1) -&gt; 2 (1, 0) -&gt; NA mat &lt;- matrix(0, 10, 2) mat[c(5, 8, 9, 12, 15, 16, 17, 19)] &lt;- 1 mat #&gt; [,1] [,2] #&gt; [1,] 0 0 #&gt; [2,] 0 1 #&gt; [3,] 0 0 #&gt; [4,] 0 0 #&gt; [5,] 1 1 #&gt; [6,] 0 1 #&gt; [7,] 0 1 #&gt; [8,] 1 0 #&gt; [9,] 1 1 #&gt; [10,] 0 0 You have to use the following matrix to do so: (decode &lt;- matrix(c(0, NA, 1, 2), 2)) #&gt; [,1] [,2] #&gt; [1,] 0 1 #&gt; [2,] NA 2 Start by doing it for one row, then by using apply(). Finally, replace it by a special accessor. Expected result: #&gt; [1] 0 1 0 0 2 1 1 NA 2 0 3.4 Environments and scoping The final section of this chapter is about environments and scoping. These concepts may be confusing in the beginning; if you are still puzzled about environments and scoping at the end of this section, don’t get frustrated. We will provide some references to other materials that you can read at the end of this section. Let us dive right into it: Environments associate a set of names with a set of values. You can think of an environment as a list, but with four important exceptions: Every name in an environment is unique. The names in an environment are not ordered. Every environment has a parent environment. Environments have reference semantics. Let us take a closer look at exception 3: Every environment has a parent environment. One environment doesn’t follow that rule: the empty environment. The empty environment is the ultimate ancestor of all other environments. All other environments have parents. Most environments have grandparents (the parent’s parent), and the ancestors of an environment include all parent environments up to the empty environment. When R is looking for a variable, it will start looking for that variable inside the current environment. If R cannot find the variable in the current environment, it will look in the parent environment. If the variable doesn’t exist in the parent environment either, R will look in the parent environment of the parent, and so on. Let us consider an example to make this point clearer. h &lt;- function() { x &lt;- 10 f &lt;- function() { x + 1 } f() } x &lt;- 100 h() #&gt; [1] 11 To evaluate the function h() above, R needs to evaluate the function f(). The function f() simply returns x + 1. But in order to compute x + 1, R needs to find the value associated with the name x. R will start looking in the current environment; the function body of f(): f &lt;- function() { x + 1 } x is not defined in the body of f(), hence R will look for the variable in the parent environment. The parent environment of f() is h() (as f() is defined inside of h()): h &lt;- function() { x &lt;- 10 f &lt;- function() { x + 1 } f() } x is associated with the value 10 in line 2. Therefore, R takes that value to compute x + 1, and h() returns 11. The principle that R will look for a name in the parent environment if it is not found in the current environment is what is called lexical scoping. More precisely: Lexical scoping is the set of rules that determines how R finds the value associated with a name. The lexical in lexical scoping comes from the computer science term lexing, which is the process of breaking down a string into meaningful pieces that the programming language can understand. In short, R’s lexical scoping follows these four primary rules; Dynamic lookup: In R, dynamic lookup focuses on where to look for values, not when to look for them. In other words, R looks for values when the function is run, not when the function is created. For example, defining the following function won’t throw and error; even if x has not been defined yet: fct &lt;- function() { x + 1 } But once we call fct(), R tries to look for x and returns an error, if x does not exist: fct() #&gt; Error in fct(): object &#39;x&#39; not found A fresh start: Every time a function is called, a new environment is created to host its execution. This means that each invocation is completely independent of all prior invocations: fct &lt;- function() { if (!exists(&quot;x&quot;)) x &lt;- 1 else x &lt;- x + 1 x } fct() #&gt; [1] 1 fct() #&gt; [1] 1 You are, however, able to circumvent this using the super assignment &lt;&lt;-. Super assignment never creates a variable in the current environment, but modifies an existing variable found in a parent environment. If the variable is not found in a parent environment, super assignment will create one in the global environment: fct &lt;- function() { if (!exists(&quot;x&quot;)) x &lt;&lt;- 1 else x &lt;&lt;- x + 1 x } fct() #&gt; [1] 1 fct() #&gt; [1] 2 fct() #&gt; [1] 3 Functions versus variables: Whenever a function and a non-function in two different environments share the same name, R ignores non-function objects when looking for that value: f1 &lt;- function(x) x + 10 f2 &lt;- function() { f1 &lt;- 30 f1(f1) } f2() #&gt; [1] 40 Name masking: Name masking is the basic principle of lexical scoping. It controls that names defined inside a function mask names defined outside that function. Name masking is related closely to the third exception Every environment has a parent environment mentioned in connection to environments in the beginning of this section. The four rules defining R’s lexical scoping have some implications that may be confusing at first. As mentioned above, the output of a function may depend on the objects defined outside of the function: fct &lt;- function() { x + 1 } x &lt;- 15 fct() #&gt; [1] 16 x &lt;- 10 fct() #&gt; [1] 11 Conversely, lexical scoping can also lead to a function being independent of the objects outside of the function: fct &lt;- function() { x &lt;- 5 x + 1 } x &lt;- 15 fct() #&gt; [1] 6 We generally want to avoid this behavior, as it can lead to errors and misunderstandings. Furthermore, lexical scoping may lead to erroneous outputs. For example, if you make a spelling mistake in your code and write y instead of z in the body of the function, the output will not be as expected: fct &lt;- function(x, z) { x^y # instead of x^z } x &lt;- 2 y &lt;- 3 z &lt;- x + y fct(x, z) #&gt; [1] 8 Another potential problem to be aware of is that you can accidentally redefine functions without noticing: c &lt;- function(...) paste0(...) c(1, 2, 3) #&gt; [1] &quot;123&quot; The function c() defined above will mask the base R function c() combining values into a vector (R will look for the name c in the current environment first). If this happens, you need to tell R to look for the original function in the package that includes that function in order to use it, i.e.: base::c(1, 2, 3) #&gt; [1] 1 2 3 Fortunately, you can easily remove the duplicated function from the current environment with rm(), as R will start looking for the name in the current environment. When calling the function c() afterwards, the name c is no longer defined in the current environment, and R will look for the name in the parent environments: rm(c) c(1, 2, 3) #&gt; [1] 1 2 3 If you are still confused about environments and scoping, we recommend you take a look at these other materials: Chapter 6 Functions of Advanced R by Hadley Wickham. Chapter 7 Environments of Advanced R by Hadley Wickham. Chapter 15 Scoping Rules of R of R Programming for Data Science by Roger Peng. This chapter also comes with video versions of Section 15.1 and Section 15.3. 3.5 Summary Real numbers are represented as floating-point numbers, which can lead to floating-point errors. Use all.equal() or dplyr::near() instead of == to test if two objects are equal. ... is a special argument that allows functions to take any number of arguments. ... is greedy and any misspelled or non-existing arguments will be passed on without raising an error. The function sample() can be used with a vector, a single number, or even a real number. Internally, sample() turns any (real) number x into a sequence starting with 1 and increasing with 1 until the upper limit x is reached. The colon operator from:to can be used to generate sequences staring from from and ending with to in steps of 1 or -1 (similar to seq()). All R objects have a type. The four most common types of a basic (atomic) vector are logical, integer, double, and character. Atomic vectors are one-dimensional and homogeneous (i.e. all contents must be of the same type). Generic vectors (or lists) are one-dimensional and heterogeneous (i.e. they can contain different types). Two-dimensional matrices and multi-dimensional arrays are obtained from atomic vectors by adding the attribute dim. Data frames are generic vectors whose contents are equal-length vectors. Per default, data frames have three attributes: names, class, and row.names. R has class-specific functions, called methods. You can define your own attributes using the function structure(). Data frames can be subsetted like a one-dimensional structure (where it behaves like a list), or a two-dimensional structure (where it behaves like a matrix). The [ accessor can be used on vectors, matrices, arrays, lists and data frames to extract or replace subsets of the data with the same class. The [[ accessor can be used on vectors, matrices, arrays, lists and data frames to access or replace a single element. The $ accessor can be used on lists and data frames to access or replace single elements. Environments associate a set of names with a set of values. If a name is not found in the current environment, R will look for the name in the parent environments. Lexical scoping is the set of rules that determines how R finds the value associated with a name, and it can be quite confusing… Useful resources Computer Floating-Point Arithmetic and round-off errors, article by Kausal Kaluarachchi. Chapter 14 Functions of R Programming for Data Science by Roger Peng. "],["rmarkdown.html", "Chapter 4 R Markdown 4.1 R Markdown basics 4.2 Producing a complete report 4.3 Summary Useful resources", " Chapter 4 R Markdown When writing package documentations with roxygen2, building websites for R packages with pkgdown, or building a personal website, you will not be able to get past R Markdown. R Markdown is rightly used everywhere; Indeed, these materials are written in R Markdown. But what is R Markdown? R Markdown is a file format for making reproducible, dynamic documents with R. A single R Markdown file can be used to save and execute code, and to generate high quality reports that can be shared with an audience. An R Markdown document is written in Markdown and contains plain text and embedded R code and results. In this chapter, we will take a closer look at R Markdown. What is Markdown? Markdown is a simple markup language with plain text formatting syntax. And what is a markup language? It is a text-encoding system: A set of symbols is inserted in a text document to control its structure, formatting, etc. You probably know HTML; the standard markup language for creating Web pages. The extension of a Markdown file is typically .md, but a Markdown document can be converted to many formats (including HTML, PDF, and MS_Word). The original version of Markdown was created by John Gruber in 2004; completely independent of R. John Gruber’s aim was to create a markup language that was easy to read and easy to write. He may have overshot the target; The original version of Markdown was often found overly simple and not suitable to write highly technical documents. Fortunately, two years later, John MacFarlane created the universal document converter pandoc. In this connection, the Markdown syntax was significantly enriched, making Markdown an excellent authoring framework for data science. Adding R to Markdown R Markdown is an extension of the markdown syntax that enables R code to be embedded in the document. The typical extension for an R Markdown file is .Rmd. Converting an R Markdown document to a specific output format requires two steps: The .Rmd file needs to be send to knitr, which executes the R code chunks and creates a new markdown (.md) document including the R code and its output. Afterwards, the markdown file generated by knitr needs to be processed by pandoc, which is responsible for creating the finished file. Fortunately, we don’t have to perform these steps every time we want to render an R Markdown document. The package rmarkdown, which is automatically installed and loaded in RStudio, provides a function that performs the processing steps for you; the function is called render(). Moreover, RStudio has a Knit button () at the top of the Source pane that enables you to render an .Rmd file and preview it with a single click (or keyboard shortcut Ctrl+Shift+K / Shift+Command+K). The only drawback of using R Markdown is that help is not always available through the help() function. R Markdown integrates a variety of R packages and external tools; making it difficult to provide help for everything. Instead, you should consider the R Markdown Reference Guide, the R Markdown Cheat Sheet (an older version can be found here), and the rmarkdown website, which is also made with R Markdown (of course). 4.1 R Markdown basics Now that we have established what R Markdown is and what it can be used for, let us look at what a R Markdown document looks like. To create a new R Markdown document, you can either Go to File -&gt; New File -&gt; R Markdown… Click on in the upper-left corner of the RStudio menu (above the Source pane) and select R Markdown… Open a blank text document and save this file with the extension .Rmd, i.e. [file_name].Rmd. Click on New Blank File in the Files tab of the Output pane and select R Markdown… to create a file in the current directory. Your browser does not support the video tag. Using options one and two will open a pop-up window that looks like this: Figure 4.1: How to create an R Markdown file If you want to create an empty document without any pre-defined options, click on Create Empty Document in the lower-left corner. You can also create an HTML, PDF, or Word document, presentations (ioslides, Slidy, Beamer or PowerPoint), interactive Shiny documents or presentations, or open R Markdown templates using the menu to the left and the suggested default output formats. Finally, you can specify a title, author and date. Once you have selected the desired output format and updated the title, author and date, select OK. RStudio will now open an R Markdown document that looks similar to the one shown below: The document contains three important types of content: An (optional) YAML header Chunks of R code Text mixed with simple text formatting In the following, we will explore each component in more detail. The YAML header An R Markdown document starts with an (optional) YAML header surrounded by a line of three hyphens ---. This is where you can specify (or update) metadata about the document and rendering instructions. When you create an R Markdown file using the wizard shown in Figure 4.1, RStudio writes the YAML header for you. However, you can still update the existing options or add other metadata. Some commonly used YAML metadata options are: title : A descriptive main title. author : Name of the author(s). You can use lists for multiple authors and for adding other metadata, for example: author: - Name_1 - Name_2 author: - name: Name_1 - affiliation: University of Somewhere - name: Name_2 - affiliation: Uiversity of Somewhere else date : The date shown in the document. You can write a date or execute R code to update the date automatically. date: &quot;`r format(Sys.time(), &#39;%d %B, %Y&#39;)`&quot; date: &quot;`r lubridate::today()`&quot; abstract : A summary of the analyses. Multiple paragraphs can be specified but they must be indented and preceded by |: abstract: | The first paragraph of this abstract. The second paragraph of the abstract. output : Document specific YAML options. The first option specified here needs to be the document type (e.g. html_document in the example above). A full list of supported document types can be found in colored box at the end of this section. Each output format can be accompanied with several format options. All these format options must be indented, e.g. output: html_document: toc: true Some of the most commonly used document specific options are: toc : true/false to show table of contents. toc_debth : A number determining how many subheadings will be visible in the table of contents. Defaults to three. toc_float : true/false determining whether the table of contents stays visible when scrolling down. theme : The overall look of the document. You can see a list of available R Markdown Themes in Appendix F R Markdown Themes of rstudio4edu by Desirée De Leon and Alison Hill, or in the R Markdown Theme Gallery created by Andrew Zieffler. Supported document types: beamer_presentation context_document github_document html_document ioslides_presentation latex_document md_document odt_document pdf_document powerpoint_presentation rtf_document slidy_presentation word_document Other extension packages provide more output formats. However, if you want to use an output format from an extension package, you have to include the package name in the YAML header: output: tufte::tufte_html R code chunks Following the metadata is the body of the R Markdown file. The second important type of content is found in the body; namely chunks of R code surrounded by ```{r} and ```. Following the three ```in the beginning is {r}. This tells Markdown that the code chunk contains R code. Besides R, knitrcan execute code written in Python, SQL, Bash, Rcpp, Stan, JavaScript and CSS. Simply replace {r} at the top of the code chunk with the name of the desired language. You can insert a chunk in three different ways: By manually typing the chunk delimiters ```{r} and ``` By clicking the insert chunk icon in the editor toolbar at the top of the Source pane or by using the keyboard shortcut Ctrl+Alt+I / Command+Option+I. Even though you are working within an R Markdown document, you can still execute current line/selection of code in a code chunk using the keyboard shortcut Ctrl+Enter / Command+Return. If you want to run all code in a chunk, you can click in the upper-right corner of the code chunk or use the shortcut Ctrl+Shift+Enter / Command+Shift+Return. When you run code in a chunk, the output is displayed in the console as usual, and all objects are stored in the current environment. However, RStudio will also show the output below the code chunk: You can customise the chunk output with options specified in the chunk header ```{r}. knitr provides almost 60 options that you can use to customise code chunks. The most important options are: eval : Whether to evaluate the code and include its results. Defaults to TRUE. echo : Whether to display code along with its results. Defaults to TRUE. include : Whether to show the code and its results in the final document. Defaults to TRUE. This is used for setup code. warning : Whether to display warnings. Defaults to TRUE. error : Whether to display errors. Defaults to FALSE. message : Whether to display messages. Defaults to TRUE. tidy : Whether to reformat code in a tidy way when displaying it. Defaults to FALSE. collapse : Whether to merge text output and source code into a single code block in the output. Defaults to FALSE. results : Controls how to display the text results. Defaults to markup. cache : Whether to cache results for future renders. Defaults to FALSE. comment : Comment character to preface results with. Defaults to ##. fig.width : Width in inches for plots created in chunk. Defaults to 7. fig.height : Height in inches for plots created in chunk. Defaults to 7. fig.align : The alignment of plots. Defaults to default, i.e. no alignment adjustments are made. You can find all options in the package documentation for knitr. Plain text with simple text formatting The last important type of content often constitutes most of the body of an R Markdown file: plain text mixed with simple text formatting. In the following, we will provide a quick overview over the most commonly used R Markdown syntax: Syntax Output plain text plain text *italics* or _italics_ italics **bold** or __bold__ bold subscipt~2~ subscipt2 superscript^2^ superscript2 ~~strikethrough~~ strikethrough endash: -- endash: – emdash: --- emdash: — inline R code: ` r mean(1:4) ` inline R code: 2.5 inline equation: $A = \\pi \\times r^{2}$ inline equation: \\(A = \\pi \\times r^{2}\\) image: ! [optional caption text] (path/to/image.png) image: [link](https://rmarkdown.rstudio.com/) link # 1st level header 1st level header ## 2nd level header 2nd level header ### 3rd level header 3rd level header #### 4th level header 4th level header ##### 5th level header 5th level header ###### 6th level header 6th level header * Bullet list item 1 - Bullet list item 2 + Item 2a + Item 2b Bullet list item 1 Bullet list item 2 Item 2a Item 2b 1. Numbered list item 1 1. Item 2. The numbers are incremented automatically in the output 1. Item 2a 1. Item 2b Numbered list item 1 Item 2. The numbers are incremented automatically in the output Item 2a Item 2b &gt; block quote block quote First Header | Second Header -----------------|----------------- Content Cell | Content Cell Content Cell | Content Cell First Header Second Header Content Cell Content Cell Content Cell Content Cell Finally, you can start a new paragraph by ending a line with four spaces, and you can insert a horizontal rule (or insert a slide break) with three or more asterisks (***) or dashes (---) You can find a similar list in the article Markdown Basics on the RMarkdown website. 4.2 Producing a complete report To generate a complete report containing all text, code and results, either run the render() command specifying the name of the file you want to render: rmarkdown::render(&quot;my_file.Rmd&quot;, output_format = &quot;html_document&quot;) use the knit button ( Knit) at the top of the Source pane or use the keyboard shortcut Ctrl+Shift+K / Shift+Command+K. In addition to rendering the file, the knit button and the keyboard shortcut also show a preview of the output in the Output pane. All three methods generate a self-contained file that you can share with others in the directory of the input file. Exercise Make your own website with R Markdown This exercise is based on the exercise from Section 2.3. You need an R Studio project cloned from Florian Privé’s GitHub repository rmarkdown-website-template to do this exercise. If you haven’t cloned the repository, go back to Section 2.3 and go through the exercise Fork a repository before you continue with this exercise. Open the R Studio project that is linked to the GitHub repository [YOURGITHUBNAME].github.io (where [YOURGITHUBNAME] represents your GitHub username). Build the website by running rmarkdown::render_site(encoding = \"UTF-8\") or by using the keyboard shortcut Ctrl+Shift+B / Shift+Command+B. Commit and push all new or updated files to your GitHub repository. The first time you build the website, a full directory (site_libs/) is created. Trying to add all the files from this directory to a commit can make RStudio freeze. If this happens, restart R Studio and run rm .git/index.lock in the terminal of R Studio (the terminal is part of the Console pane). Afterwards, run git add . in the terminal; This will add all new files for you to commit (you can see all the added files in the Git panel of the Environments pane after refreshing it). Change the content of your website by modifying _site.yml, index.Rmd, about.Rmd, cv.Rmd and CV.pdf. Build your website again (see Step 2) and commit &amp; push everything to the GitHub repository. At any point, you can preview your website locally by rendering your site and opening the generated HTML files in your Web Browser. You can also see your website at https://YOURGITHUBNAME.github.io/. If you need some inspiration, here are some websites created with R Markdown: Modern Applied Data Analysis (MADA) Lucy D’Agostino McGowan’s personal website The R user group in Grenoble And to learn more about what pages should be included on your website, read this blog post by Animate Your Science. 4.3 Summary R Markdown is a file format for making reproducible, dynamic documents with R. An R Markdown document is written in Markdown and contains plain text and embedded R code along with results. The typical extension for an R Markdown file is .Rmd. To open a new R Markdown document, go to File -&gt; New File -&gt; R Markdown… or click on in the upper-left corner of the RStudio menu and select R Markdown… . R Studio will launch a wizard that you can use to pre-populate the file with useful content. An R Markdown document starts with an (optional) YAML header where you can specify (or update) metadata about the document and rendering instructions. The body of an R Markdown file can contain R code chunks surrounded by ```{r} and ``` You can customise the chunk output with options specified in the chunk header ```{r}. The plain text in an R Markdown file can be formatted with R Markdown syntax. To generate a complete report containing all text, code and results, use the knit button ( Knit) at the top of the Source pane or the keyboard shortcut Ctrl+Shift+K / Shift+Command+K. Useful resources R Markdown Quick Tour Introduction to R Markdown by Garrett Grolemund R Markdown: The Definitive Guide by Yihui Xie, J. J. Allaire and Garrett Grolemund {R Markdown}, a presentation by Florian Privé and Julyan Arbel. Chapter 27 R Markdown of R for Data Science by Hadley Wickham and Garrett Grolemund. R Markdown Websites "],["tidyverse.html", "Chapter 5 Data analysis with the tidyverse 5.1 Program 5.2 Other chapters from this book 5.3 Other resources 5.4 Other “tidy” packages 5.5 Summary Useful resources", " Chapter 5 Data analysis with the tidyverse The tidyverse is an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures. For learning how to do data analysis from importing data and tidying it to analyzing it and reporting results, we will use book R for Data Science. You can find most of the exercise solutions there. 5.1 Program my {ggplot2} presentation + exercises from data visualization with {ggplot2} tibbles data transformation with {dplyr} tidy data will rationalize the concept of “tidy” data that is used in the tidyverse and that is easier to work with relational data will give you tools to join information from several datasets more if time allows it (see below) 5.2 Other chapters from this book The other chapters of R for Data Science book are very interesting and you should read them. Unfortunately, we won’t have time to cover them in class. A brief introduction of what you could learn: data import will give you tools to import data (e.g. as a replacement of read.table) strings will help you work with strings and regular expressions factors will help you work with factors dates and times will help you work with dates and times many models will introduce the concept of list-columns that enable you to store complex objects in a structured way inside a data frame databases: packages {DBI} and {dbplyr} + RStudio’s webpage 5.3 Other resources [IN FRENCH] introduction à R et au tidyverse package {tidylog} provides verbose feedback about {dplyr} and {tidyr} operations comparing dplyr functions to their base R equivalents summarize and mutate multiple columns why use purrr::map instead of lapply? reorder those bars the lesser known stars of the tidyverse summary statistics of variables live data analysis by Hadley 5.4 Other “tidy” packages analysis of text data: package {tidytext} with the associated book, analysis of financial data: package {tidyquant}, analysis of time series data: package {tidytime}, a collection of packages for modeling and machine learning using tidyverse principles: package {tidymodels}, a tidy API for graph manipulation: package {tidygraph}, many other packages.. 5.5 Summary Useful resources "],["performance.html", "Chapter 6 Performance 6.1 R’s memory management 6.2 Early advice 6.3 Vectorization 6.4 Rcpp 6.5 Linear algebra 6.6 Algorithms &amp; data structures 6.7 Exercises 6.8 Parallel computing", " Chapter 6 Performance Some resources used here or for further reading: Advanced R Efficient R programming The people who say that “R is just always slow” are usually not great R programmers. It is true that writing inefficient R code is easy, yet writing efficient R code is also possible when you know what you’re doing. In this chapter, you will learn how to write R(cpp) code that is fast. 6.1 R’s memory management Read more with this chapter of Advanced R. 6.1.1 Understanding binding basics x &lt;- c(1, 2, 3) It’s creating an object, a vector of values, c(1, 2, 3). And it’s binding that object to a name, x. y &lt;- x There are now two names for the same object in memory. 6.1.2 Copy-on-modify x &lt;- c(1, 2, 3) y &lt;- x y[3] &lt;- 4 x #&gt; [1] 1 2 3 The object in memory is copied before being modified, so that x is not modified. 6.1.3 Copy-on-modify: what about inside functions? f &lt;- function(a) { a } x &lt;- c(1, 2, 3) z &lt;- f(x) f2 &lt;- function(a) { a[1] &lt;- 10 a } z2 &lt;- f2(x) cbind(x, z2) #&gt; x z2 #&gt; [1,] 1 10 #&gt; [2,] 2 2 #&gt; [3,] 3 3 The input parameter is not modified; you operate on a local copy of a = x in f2(). 6.1.4 Lists It’s not just names (i.e. variables) that point to values; elements of lists do too. l1 &lt;- list(1, 2, 3) l2 &lt;- l1 6.1.5 Copy-on-modify for lists? l2[[3]] &lt;- 4 Only the third element needs to be copied. 6.1.6 Data frames Data frames are lists of vectors. d1 &lt;- data.frame(x = c(1, 5, 6), y = c(2, 4, 3)) d2 &lt;- d1 d2[, 2] &lt;- d2[, 2] * 2 # modify one column d3 &lt;- d1 d3[1, ] &lt;- d3[1, ] * 3 # modify one row By modifying the first row, you’re modifying the first element of all vectors, therefore the full data frame is copied.. 6.2 Early advice 6.2.1 NEVER GROW A VECTOR Example computing the cumulative sums of a vector: x &lt;- rnorm(2e4) # Try also with n = 1e5 system.time({ current_sum &lt;- 0 res &lt;- c() for (x_i in x) { current_sum &lt;- current_sum + x_i res &lt;- c(res, current_sum) } }) #&gt; user system elapsed #&gt; 0.23 0.29 0.86 Here, at each iteration, you are reallocating a vector (of increasing size). Not only computations take time, memory allocations do too. This makes your code quadratic with the size of x (if you multiply the size of x by 2, you can expect the execution time to be multiplied by 4, for large sample sizes), whereas it should be only linear. What happens is similar to if you would like to climb these stairs, you climb one stair, go to the bottom, then climb two stairs, go to bottom, climb three, and so on. That takes way more time than just climbing all stairs at once. A good solution is to always pre-allocate your results (if you know the size): system.time({ current_sum &lt;- 0 res2 &lt;- double(length(x)) for (i in seq_along(x)) { current_sum &lt;- current_sum + x[i] res2[i] &lt;- current_sum } }) #&gt; user system elapsed #&gt; 0 0 0 all.equal(res2, res) #&gt; [1] TRUE If you don’t know the size of the results, you can store them in a list and merge them afterwards: system.time({ current_sum &lt;- 0 res3 &lt;- list() for (i in seq_along(x)) { current_sum &lt;- current_sum + x[i] res3[[i]] &lt;- current_sum } }) #&gt; user system elapsed #&gt; 0.00 0.00 0.01 all.equal(unlist(res3), res) #&gt; [1] TRUE With recent versions of R (&gt;= 3.4), you can efficiently grow a vector using system.time({ current_sum &lt;- 0 res4 &lt;- c() for (i in seq_along(x)) { current_sum &lt;- current_sum + x[i] res4[i] &lt;- current_sum } }) #&gt; user system elapsed #&gt; 0 0 0 all.equal(res4, res) #&gt; [1] TRUE Assigning to an element of a vector beyond the current length now over-allocates by a small fraction. The new vector is marked internally as growable, and the true length of the new vector is stored in the truelength field. This makes building up a vector result by assigning to the next element beyond the current length more efficient, though pre-allocating is still preferred. The implementation is subject to change and not intended to be used in packages at this time. (NEWS) An even better solution would be to avoid the loop by using a vectorized function: system.time(res5 &lt;- cumsum(x)) #&gt; user system elapsed #&gt; 0 0 0 all.equal(res5, res) #&gt; [1] TRUE x &lt;- rnorm(1e7) system.time(cumsum(x)) #&gt; user system elapsed #&gt; 0.04 0.00 0.08 As a second example, let us generate a matrix of uniform values (max changing for every column): n &lt;- 1e3 max &lt;- 1:1000 system.time({ mat &lt;- NULL for (m in max) { mat &lt;- cbind(mat, runif(n, max = m)) } }) #&gt; user system elapsed #&gt; 0.58 1.43 2.66 apply(mat, 2, max)[1:10] #&gt; [1] 0.9999517 1.9995595 2.9968458 3.9995284 4.9891299 5.9991612 6.9914785 7.9975349 #&gt; [9] 8.9988360 9.9971460 Instead, we should pre-allocate a matrix of the right size: system.time({ mat3 &lt;- matrix(0, n, length(max)) for (i in seq_along(max)) { mat3[, i] &lt;- runif(n, max = max[i]) } }) #&gt; user system elapsed #&gt; 0.02 0.00 0.01 apply(mat3, 2, max)[1:10] #&gt; [1] 0.9999039 1.9994663 2.9962688 3.9989532 4.9952994 5.9967417 6.9956571 7.9995939 #&gt; [9] 8.9914785 9.9829999 Or we could use a list instead. What is nice with using a list is that you don’t need to pre-allocate. Indeed, as opposed to atomic vectors, each element of a list is in different places in memory so that you don’t have to reallocate all the data when you add an element to a list. system.time({ l &lt;- list() for (i in seq_along(max)) { l[[i]] &lt;- runif(n, max = max[i]) } mat4 &lt;- do.call(&quot;cbind&quot;, l) }) #&gt; user system elapsed #&gt; 0.01 0.00 0.01 apply(mat4, 2, max)[1:10] #&gt; [1] 0.9999257 1.9974230 2.9978316 3.9994049 4.9959614 5.9978416 6.9937523 7.9825662 #&gt; [9] 8.9941963 9.9989175 Instead of pre-allocating yourself, you can use sapply (or lapply and calling do.call() after, as previously done): system.time( mat4 &lt;- sapply(max, function(m) runif(n, max = m)) ) #&gt; user system elapsed #&gt; 0.01 0.00 0.02 apply(mat4, 2, max)[1:10] #&gt; [1] 0.9999742 1.9989495 2.9981049 3.9997492 4.9962149 5.9901385 6.9983507 7.9980954 #&gt; [9] 8.9999263 9.9876734 Don’t listen to people telling you that sapply() is a vectorized operation that is so much faster than loops. That’s false, and for-loops can actually be much faster than sapply() when using just-in-time (JIT) compilation. You can learn more with this blog post. 6.2.2 Use the right function Often, in order to optimize your code, you can simply find the right function to do what you need to do. For example, rowMeans(x) is much faster than apply(x, 1, mean). Similarly, if you want more efficient functions that apply to rows and columns of matrices, you can check package {matrixStats}. Another example is when reading large text files; in such cases, prefer using data.table::fread() rather than read.table(). Generally, packages that uses C/Rcpp are efficient. 6.2.3 Do not try to optimize everything “Programmers waste enormous amounts of time thinking about, or worrying about, the speed of noncritical parts of their programs, and these attempts at efficiency actually have a strong negative impact when debugging and maintenance are considered.” — Donald Knuth. If you try to optimize each and every part of your code, you will end up losing a lot of time writing it, and it will probably make your code less readable. R is great at prototyping quickly because you can write code in a concise and easy way. Start by doing just that. If performance matters, then profile your code to see which part of your code is taking too much time and optimize only this part! Learn more on how to profile your code in RStudio in this article. 6.3 Vectorization I call vectorized a function that takes vectors as arguments and operate on each element of these vectors in another (compiled) language (such as C, C++ and Fortran). Again, sapply() is not a vectorized function (cf. above). Take this code: N &lt;- 10e3; x &lt;- runif(N); y &lt;- rnorm(N) res &lt;- double(length(x)) for (i in seq_along(x)) { res[i] &lt;- x[i] + y[i] } As an interpreted language, for each iteration res[i] &lt;- x[i] + y[i], R has to ask: what is the type of x[i] and y[i]? can I add these two types? what is the type of x[i] + y[i] then? can I store this result in res or do I need to convert it? These questions must be answered for each iteration, which takes time. Some of this is alleviated by JIT compilation. On the contrary, for vectorized functions, these questions must be answered only once, which saves a lot of time. Read more with Noam Ross’s blog post on vectorization. 6.3.1 Exercise Monte-Carlo integration (example from book Efficient R programming) Suppose we wish to estimate the integral \\(\\int_0^1 x^2 dx\\) using a Monte-Carlo method. Essentially, we throw darts (at random) and count the proportion of darts that fall below the curve (as in the following figure). Naively implementing this Monte-Carlo algorithm in R would typically lead to something like: monte_carlo &lt;- function(N) { hits &lt;- 0 for (i in seq_len(N)) { x &lt;- runif(1) y &lt;- runif(1) if (y &lt; x^2) { hits &lt;- hits + 1 } } hits / N } This takes a few seconds for N = 1e6: N &lt;- 2e5 system.time(res &lt;- monte_carlo(N)) #&gt; user system elapsed #&gt; 0.52 0.30 0.83 res #&gt; [1] 0.33386 Your task: find a vectorized solution for this problem: system.time(res2 &lt;- monte_carlo_vec(N)) #&gt; user system elapsed #&gt; 0.01 0.00 0.02 res2 #&gt; [1] 0.33295 6.4 Rcpp See this presentation. You have this data and this working code (a loop) that is slow mydf &lt;- readRDS(system.file(&quot;extdata/one-million.rds&quot;, package = &quot;advr38pkg&quot;)) QRA_3Dmatrix &lt;- array(0, dim = c(max(mydf$ID), max(mydf$Volume), 2)) transform_energy &lt;- function(x) { 1 - 1.358 / (1 + exp( (1000 * x - 129000) / 120300 )) } for (i in seq_len(nrow(mydf))) { # Row corresponds to the ID class row &lt;- mydf$ID[i] # Column corresponds to the volume class column &lt;- mydf$Volume[i] # Number of events, initially zero, then increment QRA_3Dmatrix[row, column, 1] &lt;- QRA_3Dmatrix[row, column, 1] + 1 # Sum energy QRA_3Dmatrix[row, column, 2] &lt;- QRA_3Dmatrix[row, column, 2] + transform_energy(mydf$Energy[i]) } Rewrite this for-loop with Rcpp. You can also try to use {dplyr} for this problem. 6.5 Linear algebra It is faster to use crossprod(X) and tcrossprod(X) instead of t(X) %*% X and X %*% t(X). Moreover, using A %*% (B %*% y) is faster than A %*% B %*% y, and solve(A, y) is faster than solve(A) %*% y. Don’t re-implement linear algebra operations (such as matrix products) yourself. There exist some highly optimized libraries for this. If you want to use linear algebra in Rcpp, try RcppArmadillo or RcppEigen. If you want to use some optimized multi-threaded linear library, you can try Microsoft R Open. 6.5.1 Exercises Compute the Euclidean distances between each of row of X and each row of Y: set.seed(1) X &lt;- matrix(rnorm(5000), ncol = 5) Y &lt;- matrix(rnorm(2000), ncol = 5) A naive implementation would be: system.time({ dist &lt;- matrix(NA_real_, nrow(X), nrow(Y)) for (i in seq_len(nrow(X))) { for (j in seq_len(nrow(Y))) { dist[i, j] &lt;- sqrt(sum((Y[j, ] - X[i, ])^2)) } } }) #&gt; user system elapsed #&gt; 0.26 0.02 0.43 Try first to remove one of the two loops using sweep() instead. Which loop should you choose to remove ideally? A solution with sweep() can take #&gt; user system elapsed #&gt; 0.03 0.00 0.06 Then, try to implement a fully vectorized solution based on this hint: \\(\\text{dist}(X_i, Y_j)^2 = (X_i - Y_j)^T (X_i - Y_j) = X_i^T X_i + Y_j^T Y_j - 2 X_i^T Y_j\\). A faster solution using outer() and tcrossprod() takes #&gt; user system elapsed #&gt; 0.00 0.00 0.02 6.6 Algorithms &amp; data structures Sometimes, getting the right data structure (e.g. using a matrix instead of a data frame or integers instead of characters) can save you some computation time. Is your algorithm doing some redundant computations making it e.g. quadratic instead of linear with respect to the dimension of your data? See exercises (section 6.7) for some insights. You can also find a detailed example in this blog post. 6.7 Exercises Generate \\(10^7\\) (start with \\(10^5\\)) steps of the process described by the formula:\\[X(0)=0\\]\\[X(t+1)=X(t)+Y(t)\\] where \\(Y(t)\\) are independent random variables with the distribution \\(N(0,1)\\). Then, calculate the percentage of \\(X(t)\\) that are negative. You do not need to store all values of \\(X\\). A naive implementation with a for-loop could be: set.seed(1) system.time({ N &lt;- 1e5 x &lt;- 0 count &lt;- 0 for (i in seq_len(N)) { y &lt;- rnorm(1) x &lt;- x + y if (x &lt; 0) count &lt;- count + 1 } p &lt;- count / N }) #&gt; user system elapsed #&gt; 0.05 0.00 0.06 p #&gt; [1] 0.88454 Try to vectorize this after having written the value of X(0), X(1), X(2), and X(3). What would be the benefit of writing an Rcpp function over a simple vectorized R function? set.seed(1) system.time(p2 &lt;- advr38pkg::random_walk_neg_prop(1e5)) #&gt; user system elapsed #&gt; 0.00 0.00 0.03 p2 #&gt; [1] 0.88454 set.seed(1) system.time(p3 &lt;- advr38pkg::random_walk_neg_prop(1e7)) #&gt; user system elapsed #&gt; 0.16 0.00 0.31 p3 #&gt; [1] 0.3400444 mat &lt;- as.matrix(mtcars) ind &lt;- seq_len(nrow(mat)) mat_big &lt;- mat[rep(ind, 1000), ] ## 1000 times bigger dataset last_row &lt;- mat_big[nrow(mat_big), ] Speed up these loops (vectorize): system.time({ for (j in 1:ncol(mat_big)) { for (i in 1:nrow(mat_big)) { mat_big[i, j] &lt;- 10 * mat_big[i, j] * last_row[j] } } }) #&gt; user system elapsed #&gt; 0.26 0.01 0.39 Why colSums() on a whole matrix is faster than on only half of it? m0 &lt;- matrix(rnorm(1e6), 1e3, 1e3) microbenchmark::microbenchmark( colSums(m0[, 1:500]), colSums(m0) ) #&gt; Unit: microseconds #&gt; expr min lq mean median uq max neval #&gt; colSums(m0[, 1:500]) 1635.501 1946.8515 2469.9160 2064.8010 2507.001 9930.602 100 #&gt; colSums(m0) 714.901 744.1015 867.0421 765.6015 1001.552 1515.701 100 Try to speed up this code by vectorizing it first, and/or by precomputing. Then, recode it in Rcpp and benchmark all the solutions you came up with. M &lt;- 50 step1 &lt;- runif(M) A &lt;- rnorm(M) N &lt;- 1e4 tau &lt;- matrix(0, N + 1, M) tau[1, ] &lt;- A for (j in 1:M) { for (i in 2:nrow(tau)) { tau[i, j] &lt;- tau[i - 1, j] + step1[j] * 1.0025^(i - 2) } } Make a fast function that counts the number of elements between a sequence of breaks. Can you do it in base R? Try also implementing it in Rcpp. How can you implement a solution whose computation time doesn’t depend on the number of breaks? [Which are the special cases that you should consider?] x &lt;- sample(10, size = 1e4, replace = TRUE) breaks &lt;- c(1, 3, 8.5, 9.5, 10) table(cut(x, breaks), exclude = NULL) # does not include first break (1) #&gt; #&gt; (1,3] (3,8.5] (8.5,9.5] (9.5,10] &lt;NA&gt; #&gt; 2006 4970 1027 944 1053 hist(x, breaks, plot = FALSE)$counts # includes first break #&gt; [1] 3059 4970 1027 944 advr38pkg::count_by_breaks(x, breaks) #&gt; [1] 2006 4970 1027 944 advr38pkg::count_by_breaks_fast(x, breaks) #&gt; [1] 2006 4970 1027 944 microbenchmark::microbenchmark( table(cut(x, breaks)), hist(x, breaks, plot = FALSE)$counts, advr38pkg::count_by_breaks(x, breaks, use_outer = TRUE), advr38pkg::count_by_breaks(x, breaks, use_outer = FALSE), advr38pkg::count_by_breaks_fast(x, breaks) ) #&gt; Unit: microseconds #&gt; expr min lq mean #&gt; table(cut(x, breaks)) 683.701 825.0510 1031.8029 #&gt; hist(x, breaks, plot = FALSE)$counts 260.502 334.3510 383.8829 #&gt; advr38pkg::count_by_breaks(x, breaks, use_outer = TRUE) 221.901 368.5515 439.6511 #&gt; advr38pkg::count_by_breaks(x, breaks, use_outer = FALSE) 129.902 176.5015 194.4100 #&gt; advr38pkg::count_by_breaks_fast(x, breaks) 112.501 153.6005 177.8270 #&gt; median uq max neval #&gt; 846.6505 929.6510 12473.801 100 #&gt; 358.3510 418.5505 682.300 100 #&gt; 421.8020 486.1510 862.701 100 #&gt; 187.7510 196.3505 284.500 100 #&gt; 167.2515 192.3020 285.901 100 x2 &lt;- sample(100, size = 1e5, replace = TRUE) breaks2 &lt;- breaks * 10 breaks3 &lt;- seq(0, 100, length.out = 100) microbenchmark::microbenchmark( advr38pkg::count_by_breaks(x2, breaks2), advr38pkg::count_by_breaks_fast(x2, breaks2), advr38pkg::count_by_breaks(x2, breaks3), advr38pkg::count_by_breaks_fast(x2, breaks3) ) #&gt; Unit: milliseconds #&gt; expr min lq mean median #&gt; advr38pkg::count_by_breaks(x2, breaks2) 1.140101 1.601650 1.855414 1.643101 #&gt; advr38pkg::count_by_breaks_fast(x2, breaks2) 1.002900 1.318351 1.527326 1.367452 #&gt; advr38pkg::count_by_breaks(x2, breaks3) 29.641301 33.800801 36.979740 35.833301 #&gt; advr38pkg::count_by_breaks_fast(x2, breaks3) 1.141501 1.301451 1.610745 1.379300 #&gt; uq max neval #&gt; 1.896451 10.735000 100 #&gt; 1.541802 9.646401 100 #&gt; 39.130501 84.437501 100 #&gt; 1.517801 10.738501 100 An R user wants to implement some sampling on a sparse matrix and provides this working code: N &lt;- 2000 system.time({ m &lt;- Matrix::Matrix(0, nrow = N, ncol = N) for (j in 1:N) { cols &lt;- sample((1:N)[-j], 2) # pick 2 columns that are not j m[j, cols] &lt;- 1 } }) #&gt; user system elapsed #&gt; 0.45 0.02 1.05 This code is slow; can you find two major reasons why? How can you more efficiently assign 1s? A faster solution would take: #&gt; user system elapsed #&gt; 0.00 0.03 0.12 Can you use sampling with replacement (to avoid unnecessarily allocating memory) in this example? A faster solution would take: #&gt; user system elapsed #&gt; 0.02 0.00 0.01 It would be even faster using Rcpp (cf. this SO answer). Make a fast function that returns all prime numbers up to a number N. N &lt;- 1e6 system.time( primes &lt;- advr38pkg::AllPrimesUpTo(N) ) #&gt; user system elapsed #&gt; 0.14 0.26 0.65 plot(primes, pch = 20, cex = 0.5) 6.8 Parallel computing I basically always use foreach and recommend to do so. See my guide to parallelism in R with foreach. Just remember to optimize your code before trying to parallelize it. Try to parallelize some of your best solutions for the previous exercises. "],["packages.html", "Chapter 7 Packages 7.1 Resources 7.2 Project exercise 7.3 Quick start 7.4 Basic stuff 7.5 Good practices 7.6 More 7.7 Release on CRAN", " Chapter 7 Packages 7.1 Resources R Packages book (read it!) Writing R extensions, the official CRAN guide (easier to read as a bookdown) Look at popular R packages on GitHub Customizing Package Build Options Mastering Software Development in R How to develop good R packages (for open science) How to decide when to trust an R package? 7.2 Project exercise Just to experiment with making an R package, we’ll try to make a small package that implements some of the features of package {dplyr} that we learned in chapter 5. We can call this package {minidplyr}. After having read the following two sections (7.3 and 7.4), create a first function that helps you select variables of a data frame by using a character vector of variable names or an integer vector of variable positions. Which accessor could you use? Document this function and use it. Bonus (for later): can you use base R function subset to use variables names without quoting them? Check your package with Ctrl/Cmd + Shift + E and fix all problems. At this point, there should be no ERROR or WARNING, unless you did not document the previous function properly. However, you should still update the DESCRIPTION file with proper information. Do it, fix any problem, and run checks again. You could submit this package to CRAN in its present form; congratulations on your new R package! Commit everything and push to GitHub. Try to install the package from someone else using remotes::install_github(\"&lt;github-username&gt;/minidplyr\"). Learn how to make unit tests in section 7.5.1 and do that for your new function select2. Which silly cases you should test? Here, you can use usethis::use_package(\"dplyr\", type = \"Suggests\") to add package {dplyr} to the suggested packages (because you will use this package in tests only). You can see the unit tests I came up with for this function. Make a function filter2 that enables to filter rows of a data frame. Add some documentation and tests for this function as well. Learn about continuous checking of your package in section 7.5.2. Follow the instructions, commit and push your changes. Go check your new badges on GitHub! Learn how to make a website out of your package in section 7.5.3 and build one for this package (or another of your packages). Implement more functions if you find this project interesting. For example, make a function mutate2 with the help of base R function transform (or within). Try to make the previous functions more general by taking many arguments at once (in ...). Make sure to keep your existing code as internal functions in order to break your code in manageable parts. 7.3 Quick start In my first package, I just put some functions I used again and again in my work. To quickly start your package, just follow these steps: Create a new RStudio project (not a package). Here, I advise you to create a new project on GitHub (with a README) and then clone it as an RStudio project. It is a good practice to put all your (public) stuff on GitHub (as we learned in section 2.3). Run the following lines of R code. usethis::use_description(list(License = &quot;GPL-3&quot;)) usethis::use_namespace() dir.create(&quot;R&quot;) usethis::use_package_doc() usethis::use_roxygen_md() Restart RStudio and change the following options. You should see a new “Build” panel next to the “Git” panel. Then use Ctrl/Cmd + Shift + B to build and reload your package. Create a simple function and put it in an .R file in the R/ directory. Inside the function, use Code -&gt; Insert Roxygen Skeleton. Build and reload your package and check the documentation of your new function and that you can use it. 7.4 Basic stuff 7.4.1 DESCRIPTION file See this chapter on the DESCRIPTION file. 7.4.2 R code Put your R code in the R/ directory. Basically it would be mostly functions. Don’t use random lines of code like in R scripts. Never explicitly load a package with library() or require(). Use usethis::use_package() to add one package to your DESCRIPTION file. Then, refer to some function with &lt;package&gt;::&lt;function&gt;() in your code, or by using the @import &lt;package&gt; or @importFrom &lt;package&gt; &lt;function&gt; roxygen tags. If one R function need another function in another R file, use the @import &lt;basename&gt;.R to make sure it is built and documented before; it is for example useful if you define new generics and methods in different files. If you modify global options() or graphics par() in a function of your package (try to avoid it), save the old values and reset when you are done: old &lt;- options(stringsAsFactors = FALSE) on.exit(options(old), add = TRUE) 7.4.3 Documentation Documentation is super useful for other people (including future-you, in 6 months when you won’t remember what you implemented in your package). Make sure to document your code as soon as you write it, otherwise you will never do it. Forget about the man/ (manual) directory, files in this directory will be automatically generated thanks to the roxygen comments you use on top of your R functions. Learn more with this chapter. Note that you can now use the Markdown syntax in the documentation. For example, instead of having to use \\code{foo}, you can directly use `foo` in the roxygen comments. To use (and export) functions already implemented in other packages, for example the pipe from package {magrittr}, you can use usethis::use_package(\"magrittr\") and put the following code somewhere in an R file of your package. #&#39; @importFrom magrittr %&gt;% #&#39; @export magrittr::`%&gt;%` Fun: [How to] Include a dancing banana in your R package documentation. 7.4.4 NAMESPACE file You can also forget about this for now because it should be automatically generated by {roxygen}. If you want to understand what’s going on, read this chapter. 7.5 Good practices 7.5.1 Testing You are probably already testing your code, you’re only doing it informally. The problem with this approach is that when you come back to this code in 3 months time to add a new feature, you’ve probably forgotten some of the informal tests you ran the first time around. This makes it very easy to break existing code that used to work (which you should avoid as much as you can). A very good practice is to use unit tests. Read this chapter. To make your first unit tests, use usethis::use_test() while having open the R file you want to test. Write some unit tests, then you can run tests of your package with Ctrl/Cmd + Shift + T. 7.5.2 Continuous checking I would rarely trust a package that doesn’t use these continuous integration services. It’s good practice to check your package regularly and on different Operating Systems (OS). Learn more about the different checks there. An easy way to regularly check your package on GitHub is to use GitHub Actions. Indeed, each time you push to your GitHub repository, checks are run on different OS. To use this service, you can run usethis::use_github_action_check_standard(). To get the coverage of your tests, use Codecov by running usethis::use_coverage() and usethis::use_github_action(\"test-coverage\"). Finally, to prevent typos in your package and especially for non-native English speakers, it can be useful to check the spelling in your package. If you think that the word “programmation” exists and that “prefered” has only one ‘r’ at the end (I did!), you should definitely use package {spelling}. Just run spelling::spell_check_setup(); this will check spelling in your package at the end of checks. If it reports words you want to ignore, just put these words in a text file inst/WORDLIST (with one word by line). 7.5.3 Pkgdown Run usethis::use_pkgdown(). If added, remove docs from the .gitignore file. Run pkgdown:::build_site(). On GitHub, go to the settings of your repo, and enable GitHub Pages from the /docs folder. Push the new files. This will render everything that you have in this folder as a website (after 0-2 minutes). To get more information and especially to configure the website, see the documentation, as a {pkgdown} website, of course. For an example, see the website of my package {bigstatsr} and the corresponding YAML file. If you want to make a personal website, check this quick tutorial. 7.6 More 7.6.1 Rcpp We learned about Rcpp in section 6.4. To use Rcpp code in your package, just use usethis::use_rcpp() and put the 2 roxygen tags e.g. in the file R/&lt;package&gt;-package.R. Then, create .cpp files with RStudio and save them the src/ directory. Note that the // [[Rcpp::export]] makes the C++ function available to R, it doesn’t export the function as part of your package (though you could access it with &lt;package&gt;:::&lt;rcpp-fun&gt;()). If you want your package to explicitly provides an Rcpp function (as an R function), you also need roxygen comments (beginning with //' instead of #', including //' @export) on top of your Rcpp function. If you need some C++ code from another package (e.g. from package {RcppArmadillo}), normally you would use // [[Rcpp::depends(RcppArmadillo)]] #include &lt;RcppArmadillo.h&gt; In an R package, you don’t need the first line but instead you need to add the package to the LinkingTo field of the DESCRIPTION file (e.g. with usethis::use_package(\"RcppArmadillo\", \"LinkingTo\")). 7.6.2 Ignore files There are two types of ignore: Files ignored by Git, specified in the .gitignore file. For example, you don’t want to track changes for some large data files or some binaries often changing. You can ignore files by using usethis::use_git_ignore(). Files ignored during the build of your package, specified in the .Rbuildignore file. For example, in my packages, I generally have two directories called tmp-tests and tmp-save where I just put some random code that I used once during development. Checks will tell you if your package contains non-standard files or directories. Moreover, I generally ignore vignettes; they are still built as part of the {pkgdown} website. There is also a {usethis} function for this: usethis::use_build_ignore(). 7.6.3 The inst/ directory When a package is installed, everything in inst/ is copied into the top-level package directory. For example, you can have: inst/extdata/: additional external data for examples and vignettes. See section 7.6.4 for more detail. You can also use inst/testdata/ for data you need in tests. To access one file in this directory, use system.file(). For example, if you have a file inst/extdata/mydata.csv in your package, an user can find it using system.file(\"extdata\", \"mydata.csv\", package = \"&lt;package&gt;\"). inst/include: some C++ code that others can use by LinkingTo your package. For example, when you use #include &lt;Rcpp.h&gt; at the top of your Rcpp code, you’re using the code in there. inst/CITATION: how to cite the package. Learn more there. 7.6.4 External data Learn more with this book chapter. 7.7 Release on CRAN If you want your package to be on CRAN, read this chapter. "],["tidytuesday.html", "Chapter 8 TidyTuesday 8.1 Loading TidyTuesday data Inspiration 8.2 Advanced R Project - TidyFriday", " Chapter 8 TidyTuesday TidyTuesday is a weekly social data project from the Data Science Learning Community (previously called R for data science (R4DS) Online Learning Community). The aim of this activity is for learners and mentors to gather and work through the book R for Data Science by Hadley Wickham; By doing so, help R learners understand how to summarize and arrange real-world data to make meaningful charts with ggplot2, tidyr, dplyr and other tools from the tidyverse. TidyTuesday started as a podcast (you can find the podcast online) and has now become a safe and supportive space for individuals to practice their wrangling and data visualization skills independent of drawing conclusions. Every Monday morning, a data set is posted to social media (on Mastodon, LinkedIn and GitHub). The data set always comes from some source article, which means that participants learn to work with real-world data. When the data has been posted to social media, all participants have time to explore the data, create visualizations, a model, a shiny app or some other data-science related output. In fact, participants do not have to use R; data-science-related output can be created in any programming language. Finally, participants can share their output and the code that they used to generate it on social media with the hash tag #TidyTuesday. The first TidyTuesday data project was released in April 2018, and included data on US Tuition Costs. Since then, the Data Science Learning Community has posted more than 300 data sets retrieved from a variety of sources and covering many different topics; From Star Trek Timelines, to CHIP data, UFO sightings, Superbowl commercials, Groundhog predictions, and many more. You can see the full list on the TidyTuesday GitHub repository. 8.1 Loading TidyTuesday data You can access any TidyTuesday data set with the package tidytuesdayR. tidytuesdayR includes several functions: -tt_available : Lists all data sets ever released by TidyTuesday - last_tuesday : Find the most recent TidyTuesday date - tt_download : Download one or more TidyTuesday files - tt_load : Load TidyTuesday data for a specified date from GitHub. For example, you can load the TidyTuesday data from 14 January 2020 using tidytuesdayR::tt_load(&quot;2020-01-14&quot;) If the data consists of more than one file, you can decide which files to download using the argument download_files: tidytuesdayR::tt_load(&quot;2020-05-05&quot;, download_files = &quot;villagers&quot;) Inspiration You can find inspiration from previous TidyTuesday projects online. Some examples are shown below: Jake Kaupp’s contribution on Chicago Bird Collisions: Georgios Karamanis’ visualization of instant ramen reviews: Georgios Karamanis’ histogram of UFO sightings: Dr. Torsten Sprenger’s visualizations of the gender bias in scientific publishing: 8.2 Advanced R Project - TidyFriday Let’s make our own mini version of TidyTuesday. As you will present your results on Friday, we can call this project TidyFriday . Work together in teams of 2 (or 3). Choose a data set from the list of available TidyTuesday data sets (tidytuesdayR::tt_available()). Come up with a question or find interesting aspects to visualize. You can also recreate an existing visualization. Apply the functions you have learned in this course and try to learn new things to create an interesting plot. Share the resulting plot(s) and the code on GitHub. Friday afternoon, you will give a short presentation where you talk about challenges and conclusions from the plot. Presentation Make a short (5-10 min) presentation. You can simply make an HTML file from R Markdown and upload it to GitHub. The HTML file can then be previewed on http://htmlpreview.github.io/. The presentation should include: A short introduction to the data set and the variables you chose to visualize Your results and a discussion about the trends/patterns in the data If you chose to recreate a visualization, comment on the quality of the plot or potential problems The generative code and comments on the steps and transformations you applied to the data Potential other tidyverse functions or packages that were particularly useful Examples Below, you can find some examples from previous years: Alcohol Consumption LEGO sets F1 winners Baby Names UFO sightings Tornados Wealth Inequalities in the USA Eurovision Horror Movies A Package for Clinical Data A Package to read BAM files "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
